{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#quoptuna-documentation","title":"QuOptuna Documentation","text":"<p>Welcome to QuOptuna, a quantum-enhanced hyperparameter optimization framework that combines quantum computing with Optuna for advanced model tuning and explainable AI.</p>"},{"location":"index.html#overview","title":"Overview","text":"<p>QuOptuna provides a comprehensive platform for: - \ud83c\udfaf Automated hyperparameter optimization for quantum and classical ML models - \ud83d\udd0d SHAP-based explainable AI with rich visualizations - \ud83d\udcca UCI ML Repository integration for easy dataset access - \ud83d\udcdd AI-powered report generation for model analysis - \ud83d\udda5\ufe0f Interactive Streamlit interface for the complete workflow</p>"},{"location":"index.html#quick-start","title":"Quick Start","text":""},{"location":"index.html#installation","title":"Installation","text":"<p>Install QuOptuna using UV (recommended) or pip:</p> <pre><code># Using UV (recommended)\nuv pip install quoptuna\n\n# Using pip\npip install quoptuna\n</code></pre>"},{"location":"index.html#launch-the-application","title":"Launch the Application","text":"<p>Start the interactive Streamlit interface:</p> <pre><code>quoptuna --start\n</code></pre> <p>Or run directly with Python:</p> <pre><code>python -m quoptuna.frontend.app run\n</code></pre>"},{"location":"index.html#basic-python-usage","title":"Basic Python Usage","text":"<pre><code>from quoptuna import DataPreparation, Optimizer\nfrom quoptuna.backend.utils.data_utils.data import mock_csv_data\nimport pandas as pd\n\n# Load and prepare data\ndf = pd.read_csv(\"your_data.csv\")\ndf[\"target\"] = df[\"target\"].replace({0: -1, 1: 1})\n\n# Save data\nfile_path = mock_csv_data(df, tmp_path=\"data\", file_name=\"my_data\")\n\n# Prepare for training\ndata_prep = DataPreparation(\n    file_path=file_path,\n    x_cols=[col for col in df.columns if col != \"target\"],\n    y_col=\"target\"\n)\ndata_dict = data_prep.get_data(output_type=\"2\")\n\n# Run optimization\noptimizer = Optimizer(db_name=\"experiment\", study_name=\"trial_1\", data=data_dict)\nstudy, best_trials = optimizer.optimize(n_trials=100)\n\nprint(f\"Best F1 Score: {best_trials[0].value:.4f}\")\nprint(f\"Best Model: {best_trials[0].params['model_type']}\")\n</code></pre>"},{"location":"index.html#key-features","title":"Key Features","text":""},{"location":"index.html#hyperparameter-optimization","title":"\ud83c\udfaf Hyperparameter Optimization","text":"<p>Automated optimization using Optuna with support for: - Multiple quantum models (Data Reuploading, Circuit-Centric, Quantum Kitchen Sinks, etc.) - Classical baselines (SVC, MLP, Perceptron) - Multi-objective optimization - Parallel trial execution - Persistent storage with SQLite</p>"},{"location":"index.html#explainable-ai","title":"\ud83d\udd0d Explainable AI","text":"<p>Comprehensive SHAP analysis with multiple visualization types: - Bar Plot: Feature importance ranking - Beeswarm Plot: Feature value impact distribution - Violin Plot: SHAP value distributions - Heatmap: Instance-level feature contributions - Waterfall Plot: Individual prediction explanations - Confusion Matrix: Model performance visualization</p>"},{"location":"index.html#dataset-management","title":"\ud83d\udcca Dataset Management","text":"<ul> <li>UCI ML Repository: Direct access to 100+ datasets</li> <li>Custom Upload: Support for CSV files</li> <li>Automatic Preprocessing: Handle missing values, feature scaling</li> <li>Target Transformation: Binary classification support (-1/+1 encoding)</li> </ul>"},{"location":"index.html#ai-powered-reports","title":"\ud83d\udcdd AI-Powered Reports","text":"<p>Generate comprehensive analysis reports using: - Google Gemini - OpenAI GPT - Anthropic Claude</p> <p>Reports include performance metrics, SHAP interpretations, and governance recommendations.</p>"},{"location":"index.html#supported-models","title":"Supported Models","text":""},{"location":"index.html#quantum-models","title":"Quantum Models","text":"<ul> <li>Data Reuploading Classifier: Quantum circuit with data re-uploading</li> <li>Circuit-Centric Classifier: Parameterized quantum circuits</li> <li>Quantum Kitchen Sinks: Quantum feature maps</li> <li>Quantum Metric Learner: Metric learning with quantum circuits</li> <li>Dressed Quantum Circuit Classifier: Hybrid quantum-classical</li> </ul>"},{"location":"index.html#classical-models","title":"Classical Models","text":"<ul> <li>Support Vector Classifier (SVC): With multiple kernels</li> <li>Multi-Layer Perceptron (MLP): Neural network classifier</li> <li>Perceptron: Simple linear classifier</li> </ul>"},{"location":"index.html#documentation","title":"Documentation","text":"<ul> <li>User Guide - Complete walkthrough of the Streamlit interface</li> <li>API Reference - Detailed API documentation for Python usage</li> <li>Examples - Code examples for common use cases</li> <li>Changelog - Version history and updates</li> </ul>"},{"location":"index.html#workflow","title":"Workflow","text":"<p>QuOptuna provides a structured workflow:</p> <ol> <li>Dataset Selection</li> <li>Load from UCI ML Repository or upload CSV</li> <li>Configure features and target</li> <li> <p>Apply preprocessing</p> </li> <li> <p>Optimization</p> </li> <li>Prepare train/test splits</li> <li>Run hyperparameter optimization</li> <li> <p>Review best performing models</p> </li> <li> <p>Model Training</p> </li> <li>Select best trial</li> <li>Train model with optimized parameters</li> <li> <p>Evaluate performance</p> </li> <li> <p>SHAP Analysis</p> </li> <li>Calculate SHAP values</li> <li>Generate multiple visualization types</li> <li> <p>Understand feature importance</p> </li> <li> <p>Report Generation</p> </li> <li>Create AI-powered analysis</li> <li>Export results</li> <li>Share insights</li> </ol>"},{"location":"index.html#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.8+</li> <li>4GB+ RAM (8GB recommended for quantum models)</li> <li>Internet connection (for UCI datasets and LLM reports)</li> </ul>"},{"location":"index.html#dependencies","title":"Dependencies","text":"<p>Core dependencies: - <code>optuna</code> - Hyperparameter optimization - <code>streamlit</code> - Web interface - <code>shap</code> - Explainable AI - <code>pennylane</code> - Quantum computing - <code>scikit-learn</code> - Classical ML models - <code>pandas</code>, <code>numpy</code> - Data processing</p>"},{"location":"index.html#development","title":"Development","text":""},{"location":"index.html#setup","title":"Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/Qentora/quoptuna.git\ncd quoptuna\n\n# Install development dependencies\nuv pip install -e \".[dev]\"\n\n# Run tests\nuv run pytest\n\n# Run linting\nuv run ruff check .\nuv run mypy .\n</code></pre>"},{"location":"index.html#project-structure","title":"Project Structure","text":"<pre><code>quoptuna/\n\u251c\u2500\u2500 src/quoptuna/\n\u2502   \u251c\u2500\u2500 backend/         # Core optimization and model code\n\u2502   \u2502   \u251c\u2500\u2500 models/      # Model implementations\n\u2502   \u2502   \u251c\u2500\u2500 tuners/      # Optuna integration\n\u2502   \u2502   \u251c\u2500\u2500 xai/         # SHAP analysis\n\u2502   \u2502   \u2514\u2500\u2500 utils/       # Utilities\n\u2502   \u2514\u2500\u2500 frontend/        # Streamlit interface\n\u2502       \u251c\u2500\u2500 pages/       # Multi-page app\n\u2502       \u251c\u2500\u2500 app.py       # Main application\n\u2502       \u2514\u2500\u2500 support.py   # Helper functions\n\u251c\u2500\u2500 docs/                # Documentation\n\u251c\u2500\u2500 experiments/         # Example notebooks\n\u2514\u2500\u2500 tests/              # Unit tests\n</code></pre>"},{"location":"index.html#contributing","title":"Contributing","text":"<p>We welcome contributions! Please see our Contributing Guidelines.</p>"},{"location":"index.html#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>\ud83d\udc1b Report bugs and issues</li> <li>\ud83d\udca1 Suggest new features</li> <li>\ud83d\udcdd Improve documentation</li> <li>\ud83d\udd27 Submit pull requests</li> <li>\u2b50 Star the repository</li> </ul>"},{"location":"index.html#support-community","title":"Support &amp; Community","text":"<ul> <li>GitHub Issues: Report bugs or request features</li> <li>Discussions: Join the community</li> <li>Documentation: Full docs</li> </ul>"},{"location":"index.html#license","title":"License","text":"<p>QuOptuna is released under the MIT License. See LICENSE for details.</p>"},{"location":"index.html#citation","title":"Citation","text":"<p>If you use QuOptuna in your research, please cite:</p> <pre><code>@software{quoptuna,\n  title = {QuOptuna: Quantum-Enhanced Machine Learning Optimization},\n  author = {QuOptuna Team},\n  year = {2024},\n  url = {https://github.com/Qentora/quoptuna}\n}\n</code></pre>"},{"location":"index.html#acknowledgments","title":"Acknowledgments","text":"<p>Built with: - Optuna - Hyperparameter optimization framework - PennyLane - Quantum machine learning - SHAP - Explainable AI - Streamlit - Web framework</p> <p>Ready to get started? Check out the User Guide or launch the app with <code>quoptuna --start</code>!</p>"},{"location":"api_docs.html","title":"API Documentation","text":""},{"location":"api_docs.html#api-documentation","title":"API Documentation","text":""},{"location":"api_docs.html#main-api","title":"Main API","text":""},{"location":"api_docs.html#quoptuna.XAI","title":"XAI","text":"<pre><code>XAI(model: BaseEstimator, data: DataSet, config: XAIConfig | None = None)\n</code></pre> METHOD DESCRIPTION <code>__str__</code> <code>_generate_final_report</code> <code>_generate_plot</code> <code>_generate_report_images</code> <code>_get_explainer</code> <code>_get_plot_function</code> <code>_get_plot_values</code> <code>_get_shap_values</code> <code>_get_shap_values_each_class</code> <code>_handle_plot_error</code> <p>Handle plot generation errors.</p> <code>_initialize_chat</code> <code>_save_plot_to_base64</code> <code>_save_plot_to_file</code> <code>_set_shap_values_classes</code> <code>_validate_and_get_data</code> <code>_validate_shap_values_class</code> <p>Validate and get SHAP values for class-specific case.</p> <code>generate_report_with_langchain</code> <p>Generate comprehensive report using LangChain and multimodal LLM.</p> <code>get_average_precision_score</code> <p>Get the average precision score of the model.</p> <code>get_bar_plot</code> <code>get_beeswarm_plot</code> <code>get_classes</code> <p>Get model classes.</p> <code>get_classification_report</code> <p>Get the classification report of the model.</p> <code>get_cohens_kappa</code> <p>Get the cohens kappa of the model.</p> <code>get_confusion_matrix</code> <p>Get the confusion matrix of the model.</p> <code>get_f1_score</code> <p>Get the f1 score of the model.</p> <code>get_heatmap_plot</code> <code>get_log_loss</code> <p>Get the log loss of the model.</p> <code>get_mcc</code> <p>Get the mcc of the model.</p> <code>get_plot</code> <p>Generate plot with given configuration.</p> <code>get_precision</code> <p>Get the precision of the model.</p> <code>get_precision_recall_curve</code> <p>Get the precision recall curve of the model.</p> <code>get_recall</code> <p>Get the recall of the model.</p> <code>get_report</code> <p>Get the report of the model.</p> <code>get_roc_auc_score</code> <p>Get the roc auc score of the model.</p> <code>get_roc_curve</code> <p>Get the roc curve of the model.</p> <code>get_violin_plot</code> <code>get_waterfall_plot</code> <code>load_state</code> <p>Loads the state of the class from a pkl file.</p> <code>plot_confusion_matrix</code> <p>Plot confusion matrix with given configuration.</p> <code>save_state</code> <p>Saves the state of the class and its variables in a pkl file.</p> <code>validate_predict_proba</code> ATTRIBUTE DESCRIPTION <code>_classes</code> <p> </p> <code>_explainer</code> <p> TYPE: <code>Explainer | None</code> </p> <code>_predictions</code> <p> TYPE: <code>Series | None</code> </p> <code>_predictions_proba</code> <p> TYPE: <code>DataFrame | None</code> </p> <code>_shap_values</code> <p> TYPE: <code>Explanation | None</code> </p> <code>_shap_values_each_class</code> <p> TYPE: <code>dict[str, Explanation] | None</code> </p> <code>_x_test</code> <p> TYPE: <code>DataFrame | None</code> </p> <code>_y_test</code> <p> TYPE: <code>Series | None</code> </p> <code>config</code> <p> </p> <code>data</code> <p> </p> <code>data_key</code> <p> TYPE: <code>str</code> </p> <code>explainer</code> <p> TYPE: <code>Explainer</code> </p> <code>feature_names</code> <p> TYPE: <code>list[str] | None</code> </p> <code>max_display</code> <p> TYPE: <code>int</code> </p> <code>model</code> <p> </p> <code>onsubset</code> <p> TYPE: <code>bool</code> </p> <code>predictions</code> <p> TYPE: <code>Series</code> </p> <code>predictions_proba</code> <p> TYPE: <code>DataFrame</code> </p> <code>shap_values</code> <p> TYPE: <code>Explanation</code> </p> <code>shap_values_each_class</code> <p> TYPE: <code>dict[str, Explanation] | None</code> </p> <code>subset_size</code> <p> TYPE: <code>int</code> </p> <code>use_proba</code> <p> TYPE: <code>bool</code> </p> <code>x_test</code> <p> TYPE: <code>DataFrame</code> </p> <code>x_test_key</code> <p> TYPE: <code>str</code> </p> <code>y_test</code> <p> TYPE: <code>Series</code> </p> <code>y_test_key</code> <p> TYPE: <code>str</code> </p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def __init__(\n    self,\n    model: BaseEstimator,\n    data: DataSet,\n    config: XAIConfig | None = None,\n) -&gt; None:\n    if model is None:\n        msg = \"Model cannot be None\"\n        raise TypeError(msg)\n\n    self.config = config or XAIConfig()\n    self.model = model\n    self.data = data\n\n    # Explicitly declare instance attributes\n    self.use_proba: bool = self.config.use_proba\n    self.onsubset: bool = self.config.onsubset\n    self.feature_names: list[str] | None = self.config.feature_names\n    self.subset_size: int = self.config.subset_size\n    self.max_display: int = self.config.max_display\n    self.data_key: str = self.config.data_key\n    self.x_test_key: str = self.config.x_test_key\n    self.y_test_key: str = self.config.y_test_key\n\n    self._classes = self.get_classes\n    data_frame = self.data.get(self.data_key)\n    if self.feature_names is None and isinstance(data_frame, pd.DataFrame):\n        self.feature_names = list(data_frame.columns)\n\n    if self.use_proba:\n        self.validate_predict_proba()\n\n    # Initialize these as None, they'll be computed on demand\n    self._explainer: Explainer | None = None\n    self._shap_values: shap.Explanation | None = None\n    self._shap_values_each_class: dict[str, shap.Explanation] | None = None\n    self._x_test: pd.DataFrame | None = None\n    self._y_test: pd.Series | None = None\n    self._predictions: pd.Series | None = None\n    self._predictions_proba: pd.DataFrame | None = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._classes","title":"_classes  <code>instance-attribute</code>","text":"<pre><code>_classes = get_classes\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._explainer","title":"_explainer  <code>instance-attribute</code>","text":"<pre><code>_explainer: Explainer | None = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._predictions","title":"_predictions  <code>instance-attribute</code>","text":"<pre><code>_predictions: Series | None = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._predictions_proba","title":"_predictions_proba  <code>instance-attribute</code>","text":"<pre><code>_predictions_proba: DataFrame | None = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._shap_values","title":"_shap_values  <code>instance-attribute</code>","text":"<pre><code>_shap_values: Explanation | None = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._shap_values_each_class","title":"_shap_values_each_class  <code>instance-attribute</code>","text":"<pre><code>_shap_values_each_class: dict[str, Explanation] | None = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._x_test","title":"_x_test  <code>instance-attribute</code>","text":"<pre><code>_x_test: DataFrame | None = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._y_test","title":"_y_test  <code>instance-attribute</code>","text":"<pre><code>_y_test: Series | None = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config or XAIConfig()\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data = data\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.data_key","title":"data_key  <code>instance-attribute</code>","text":"<pre><code>data_key: str = data_key\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.explainer","title":"explainer  <code>property</code>","text":"<pre><code>explainer: Explainer\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.feature_names","title":"feature_names  <code>instance-attribute</code>","text":"<pre><code>feature_names: list[str] | None = feature_names\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.max_display","title":"max_display  <code>instance-attribute</code>","text":"<pre><code>max_display: int = max_display\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = model\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.onsubset","title":"onsubset  <code>instance-attribute</code>","text":"<pre><code>onsubset: bool = onsubset\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.predictions","title":"predictions  <code>property</code>","text":"<pre><code>predictions: Series\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.predictions_proba","title":"predictions_proba  <code>property</code>","text":"<pre><code>predictions_proba: DataFrame\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.shap_values","title":"shap_values  <code>property</code>","text":"<pre><code>shap_values: Explanation\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.shap_values_each_class","title":"shap_values_each_class  <code>property</code>","text":"<pre><code>shap_values_each_class: dict[str, Explanation] | None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.subset_size","title":"subset_size  <code>instance-attribute</code>","text":"<pre><code>subset_size: int = subset_size\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.use_proba","title":"use_proba  <code>instance-attribute</code>","text":"<pre><code>use_proba: bool = use_proba\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.x_test","title":"x_test  <code>property</code>","text":"<pre><code>x_test: DataFrame\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.x_test_key","title":"x_test_key  <code>instance-attribute</code>","text":"<pre><code>x_test_key: str = x_test_key\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.y_test","title":"y_test  <code>property</code>","text":"<pre><code>y_test: Series\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.y_test_key","title":"y_test_key  <code>instance-attribute</code>","text":"<pre><code>y_test_key: str = y_test_key\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.__str__","title":"__str__","text":"<pre><code>__str__()\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def __str__(self):\n    return str(self.get_report())\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._generate_final_report","title":"_generate_final_report","text":"<pre><code>_generate_final_report(chat, report, images, prompt2)\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _generate_final_report(self, chat, report, images, prompt2):\n    prompt_template = ChatPromptTemplate(\n        messages=[\n            SystemMessage(content=prompt2),\n            HumanMessage(content=\"Model Evaluation Report:\\n```\\n{report}\\n```\"),\n            MessagesPlaceholder(variable_name=\"images\"),\n        ]\n    )\n    image_messages = []\n    for plot_type, image_url in images.items():\n        image_messages.append(\n            HumanMessage(\n                content=[\n                    {\"type\": \"text\", \"text\": f\"Here is a {plot_type.replace('_', ' ')} plot:\"},\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_url, \"detail\": \"auto\"}},\n                ]\n            )\n        )\n\n    final_prompt = prompt_template.format_messages(report=str(report), images=image_messages)\n\n    response = chat(final_prompt)\n    return response.content\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._generate_plot","title":"_generate_plot","text":"<pre><code>_generate_plot(plot_type: PlotType, values, max_display: int, index: int, save_config: dict | None) -&gt; str\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _generate_plot(\n    self, plot_type: PlotType, values, max_display: int, index: int, save_config: dict | None\n) -&gt; str:\n    plt.figure()\n    if plot_type != \"waterfall\":\n        plot_func = self._get_plot_function(plot_type)\n        plot_func(values, max_display=max_display, show=False)\n    else:\n        shap.plots.waterfall(values[index], show=False)\n\n    base64_code = self._save_plot_to_base64()\n\n    if save_config is not None:  # Check if save_config exists\n        self._save_plot_to_file(save_config)\n\n    plt.close()\n    return base64_code\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._generate_report_images","title":"_generate_report_images","text":"<pre><code>_generate_report_images(num_waterfall_plots: int)\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _generate_report_images(self, num_waterfall_plots: int):\n    images: dict[str, str] = {}  # Change type hint to allow string keys\n    plot_types: list[PlotType] = [\"bar\", \"beeswarm\", \"violin\", \"heatmap\"]\n\n    try:\n        for plot_type in plot_types:\n            images[plot_type] = self.get_plot(plot_type)\n\n        if self.onsubset:\n            num_waterfall_plots = min(num_waterfall_plots, self.subset_size)\n        else:\n            num_waterfall_plots = min(num_waterfall_plots, len(self.x_test))\n\n        indices = sorted(random.sample(range(num_waterfall_plots), num_waterfall_plots))\n        for i in indices:\n            waterfall_plot_type: PlotType = \"waterfall\"\n            images[f\"{waterfall_plot_type}_{i}\"] = self.get_plot(waterfall_plot_type, index=i)\n\n        fig = self.plot_confusion_matrix()\n        img_buf = io.BytesIO()\n        fig.savefig(img_buf, format=\"png\")\n        img_buf.seek(0)\n        img_base64 = base64.b64encode(img_buf.getvalue()).decode(\"utf-8\")\n        images[\"confusion_matrix\"] = f\"data:image/png;base64,{img_base64}\"\n        plt.close(fig)\n\n    except Exception as e:\n        msg = f\"Error generating plots: {e}\"\n        raise ValueError(msg) from e\n\n    return images\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._get_explainer","title":"_get_explainer","text":"<pre><code>_get_explainer() -&gt; Explainer\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _get_explainer(self) -&gt; Explainer:\n    predict_method = self.model.predict_proba if self.use_proba else self.model.predict\n    data = self._validate_and_get_data()\n    if self.onsubset:\n        data = data.iloc[: self.subset_size]\n    return Explainer(model=predict_method, masker=data, feature_names=self.feature_names)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._get_plot_function","title":"_get_plot_function","text":"<pre><code>_get_plot_function(plot_type: PlotType)\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _get_plot_function(self, plot_type: PlotType):\n    return {\n        \"bar\": shap.plots.bar,\n        \"beeswarm\": shap.plots.beeswarm,\n        \"heatmap\": shap.plots.heatmap,\n        \"violin\": shap.plots.violin,\n    }[plot_type]\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._get_plot_values","title":"_get_plot_values","text":"<pre><code>_get_plot_values(class_index: int) -&gt; Explanation\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _get_plot_values(self, class_index: int) -&gt; shap.Explanation:\n    if class_index == -1:\n        return self.shap_values\n    if self.shap_values.values.ndim &gt; EXPECTED_SHAP_VALUES_DIM:  # noqa: PD011\n        if self.shap_values_each_class is None:\n            msg = \"No class-specific SHAP values available\"\n            raise ValueError(msg)\n        return self.shap_values_each_class[str(class_index)]\n    return self.shap_values\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._get_shap_values","title":"_get_shap_values","text":"<pre><code>_get_shap_values() -&gt; Explanation\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _get_shap_values(self) -&gt; shap.Explanation:\n    data = self._validate_and_get_data()\n    if self.onsubset:\n        data = data.iloc[: self.subset_size]\n    return self.explainer(data)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._get_shap_values_each_class","title":"_get_shap_values_each_class","text":"<pre><code>_get_shap_values_each_class(shap_values: Explanation) -&gt; dict[str, Explanation]\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _get_shap_values_each_class(\n    self, shap_values: shap.Explanation\n) -&gt; dict[str, shap.Explanation]:\n    if shap_values.values.ndim &lt; EXPECTED_SHAP_VALUES_DIM:  # noqa: PD011\n        msg = \"shap_values has less than 2 dimensions\"\n        raise TypeError(msg)\n    return {str(i): shap_values[:, :, i] for i in self.get_classes()}\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._handle_plot_error","title":"_handle_plot_error","text":"<pre><code>_handle_plot_error(plot_type: PlotType, error: Exception) -&gt; None\n</code></pre> <p>Handle plot generation errors.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _handle_plot_error(self, plot_type: PlotType, error: Exception) -&gt; None:\n    \"\"\"Handle plot generation errors.\"\"\"\n    if isinstance(error, (ValueError, TypeError, KeyError)):\n        raise error\n    msg = f\"Error generating {plot_type} plot: {error!s}\"\n    raise RuntimeError(msg) from error\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._initialize_chat","title":"_initialize_chat","text":"<pre><code>_initialize_chat(api_key: str, model_name: str, provider: str)\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _initialize_chat(self, api_key: str, model_name: str, provider: str):\n    if provider == \"google\":\n        return ChatGoogleGenerativeAI(google_api_key=api_key, model=model_name)\n    if provider == \"openai\":\n        return ChatOpenAI(openai_api_key=api_key, model_name=model_name)\n    msg = \"Invalid provider\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._save_plot_to_base64","title":"_save_plot_to_base64","text":"<pre><code>_save_plot_to_base64() -&gt; str\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _save_plot_to_base64(self) -&gt; str:\n    img_buf = io.BytesIO()\n    plt.savefig(img_buf, format=\"png\")\n    img_buf.seek(0)\n    img_base64 = base64.b64encode(img_buf.getvalue()).decode(\"utf-8\")\n    return f\"data:image/png;base64,{img_base64}\"\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._save_plot_to_file","title":"_save_plot_to_file","text":"<pre><code>_save_plot_to_file(save_config: dict) -&gt; None\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _save_plot_to_file(self, save_config: dict) -&gt; None:\n    save_path = save_config.get(\"save_path\")\n    save_name = save_config.get(\"save_name\")\n    if not save_path or not save_name:\n        return\n\n    plt.savefig(\n        Path(save_path) / save_name,\n        format=save_config.get(\"save_format\", \"png\"),\n        dpi=save_config.get(\"save_dpi\", 300),\n        bbox_inches=\"tight\",\n    )\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._set_shap_values_classes","title":"_set_shap_values_classes","text":"<pre><code>_set_shap_values_classes() -&gt; dict[str, Explanation] | None\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _set_shap_values_classes(self) -&gt; dict[str, shap.Explanation] | None:\n    if not (self.shap_values and self.shap_values.values.ndim &gt; EXPECTED_SHAP_VALUES_DIM):  # noqa: PD011\n        return None\n    return self._get_shap_values_each_class(self.shap_values)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._validate_and_get_data","title":"_validate_and_get_data","text":"<pre><code>_validate_and_get_data() -&gt; DataFrame\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _validate_and_get_data(self) -&gt; pd.DataFrame:\n    data = self.data.get(DATA_KEY)\n    if not isinstance(data, pd.DataFrame):\n        msg = f\"Expected {DATA_KEY} to be a pandas DataFrame\"\n        raise TypeError(msg)\n    return data\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI._validate_shap_values_class","title":"_validate_shap_values_class","text":"<pre><code>_validate_shap_values_class() -&gt; Explanation\n</code></pre> <p>Validate and get SHAP values for class-specific case.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def _validate_shap_values_class(self) -&gt; shap.Explanation:\n    \"\"\"Validate and get SHAP values for class-specific case.\"\"\"\n    if self.shap_values_each_class is None:\n        msg = \"No class-specific SHAP values available\"\n        raise ValueError(msg)\n    first_class = next(iter(self.get_classes()))\n    return self.shap_values_each_class[str(first_class)]\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.generate_report_with_langchain","title":"generate_report_with_langchain","text":"<pre><code>generate_report_with_langchain(api_key: str, model_name: str = 'gpt-4o', provider: str = 'google', num_waterfall_plots: int = 5)\n</code></pre> <p>Generate comprehensive report using LangChain and multimodal LLM.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def generate_report_with_langchain(\n    self,\n    api_key: str,\n    model_name: str = \"gpt-4o\",\n    provider: str = \"google\",\n    num_waterfall_plots: int = 5,\n):\n    \"\"\"Generate comprehensive report using LangChain and multimodal LLM.\"\"\"\n    chat = self._initialize_chat(api_key, model_name, provider)\n\n    report = self.get_report()\n    images = self._generate_report_images(num_waterfall_plots)\n\n    prompt2 = Path(\"prompt.txt\").read_text()\n    return self._generate_final_report(chat, report, images, prompt2)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_average_precision_score","title":"get_average_precision_score","text":"<pre><code>get_average_precision_score()\n</code></pre> <p>Get the average precision score of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_average_precision_score(self):\n    \"\"\"Get the average precision score of the model.\"\"\"\n    return average_precision_score(self.y_test, self.predictions_proba)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_bar_plot","title":"get_bar_plot","text":"<pre><code>get_bar_plot(max_display: int = DEFAULT_MAX_DISPLAY, class_index: int = -1)\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_bar_plot(self, max_display: int = DEFAULT_MAX_DISPLAY, class_index: int = -1):\n    return self.get_plot(\"bar\", max_display, class_index=class_index)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_beeswarm_plot","title":"get_beeswarm_plot","text":"<pre><code>get_beeswarm_plot(max_display: int = DEFAULT_MAX_DISPLAY, class_index: int = -1)\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_beeswarm_plot(self, max_display: int = DEFAULT_MAX_DISPLAY, class_index: int = -1):\n    return self.get_plot(\"beeswarm\", max_display, class_index=class_index)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_classes","title":"get_classes","text":"<pre><code>get_classes() -&gt; dict[int, str]\n</code></pre> <p>Get model classes.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_classes(self) -&gt; dict[int, str]:\n    \"\"\"Get model classes.\"\"\"\n    if not hasattr(self.model, \"classes_\"):\n        msg = \"Model does not have a classes_ attribute\"\n        raise TypeError(msg)\n    return self.model.classes_\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_classification_report","title":"get_classification_report","text":"<pre><code>get_classification_report()\n</code></pre> <p>Get the classification report of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_classification_report(self):\n    \"\"\"Get the classification report of the model.\"\"\"\n    return classification_report(self.y_test, self.predictions)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_cohens_kappa","title":"get_cohens_kappa","text":"<pre><code>get_cohens_kappa()\n</code></pre> <p>Get the cohens kappa of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_cohens_kappa(self):\n    \"\"\"Get the cohens kappa of the model.\"\"\"\n    return cohen_kappa_score(self.y_test, self.predictions)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_confusion_matrix","title":"get_confusion_matrix","text":"<pre><code>get_confusion_matrix()\n</code></pre> <p>Get the confusion matrix of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_confusion_matrix(self):\n    \"\"\"Get the confusion matrix of the model.\"\"\"\n    return confusion_matrix(self.y_test, self.predictions)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_f1_score","title":"get_f1_score","text":"<pre><code>get_f1_score()\n</code></pre> <p>Get the f1 score of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_f1_score(self):\n    \"\"\"Get the f1 score of the model.\"\"\"\n    return f1_score(self.y_test, self.predictions)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_heatmap_plot","title":"get_heatmap_plot","text":"<pre><code>get_heatmap_plot(max_display: int = DEFAULT_MAX_DISPLAY, class_index: int = -1)\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_heatmap_plot(self, max_display: int = DEFAULT_MAX_DISPLAY, class_index: int = -1):\n    return self.get_plot(\"heatmap\", max_display, class_index=class_index)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_log_loss","title":"get_log_loss","text":"<pre><code>get_log_loss()\n</code></pre> <p>Get the log loss of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_log_loss(self):\n    \"\"\"Get the log loss of the model.\"\"\"\n    return log_loss(self.y_test, self.predictions_proba)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_mcc","title":"get_mcc","text":"<pre><code>get_mcc()\n</code></pre> <p>Get the mcc of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_mcc(self):\n    \"\"\"Get the mcc of the model.\"\"\"\n    return matthews_corrcoef(self.y_test, self.predictions)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_plot","title":"get_plot","text":"<pre><code>get_plot(plot_type: PlotType, max_display: int = DEFAULT_MAX_DISPLAY, class_index: int = -1, index: int = 0, save_config: dict | None = None)\n</code></pre> <p>Generate plot with given configuration.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_plot(\n    self,\n    plot_type: PlotType,\n    max_display: int = DEFAULT_MAX_DISPLAY,\n    class_index: int = -1,\n    index: int = 0,\n    save_config: dict | None = None,\n):\n    \"\"\"Generate plot with given configuration.\"\"\"\n    try:\n        values = self._get_plot_values(class_index)\n        return self._generate_plot(plot_type, values, max_display, index, save_config)\n    except (ValueError, TypeError, KeyError, RuntimeError) as e:\n        self._handle_plot_error(plot_type, e)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_precision","title":"get_precision","text":"<pre><code>get_precision()\n</code></pre> <p>Get the precision of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_precision(self):\n    \"\"\"Get the precision of the model.\"\"\"\n    return precision_score(self.y_test, self.predictions)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_precision_recall_curve","title":"get_precision_recall_curve","text":"<pre><code>get_precision_recall_curve()\n</code></pre> <p>Get the precision recall curve of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_precision_recall_curve(self):\n    \"\"\"Get the precision recall curve of the model.\"\"\"\n    return precision_recall_curve(self.y_test, self.predictions_proba)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_recall","title":"get_recall","text":"<pre><code>get_recall()\n</code></pre> <p>Get the recall of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_recall(self):\n    \"\"\"Get the recall of the model.\"\"\"\n    return recall_score(self.y_test, self.predictions)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_report","title":"get_report","text":"<pre><code>get_report()\n</code></pre> <p>Get the report of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_report(self):\n    \"\"\"Get the report of the model.\"\"\"\n    report = {}\n    metrics = {\n        \"confusion_matrix\": self.get_confusion_matrix,\n        \"classification_report\": self.get_classification_report,\n        \"roc_curve\": self.get_roc_curve,\n        \"roc_auc_score\": self.get_roc_auc_score,\n        \"precision_recall_curve\": self.get_precision_recall_curve,\n        \"average_precision_score\": self.get_average_precision_score,\n        \"f1_score\": self.get_f1_score,\n        \"mcc\": self.get_mcc,\n        \"log_loss\": self.get_log_loss,\n        \"cohens_kappa\": self.get_cohens_kappa,\n        \"precision\": self.get_precision,\n        \"recall\": self.get_recall,\n    }\n\n    try:\n        for key, func in metrics.items():\n            report[key] = func()\n    except (ValueError, TypeError) as e:\n        report[key] = str(e)\n    return report\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_roc_auc_score","title":"get_roc_auc_score","text":"<pre><code>get_roc_auc_score()\n</code></pre> <p>Get the roc auc score of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_roc_auc_score(self):\n    \"\"\"Get the roc auc score of the model.\"\"\"\n    return roc_auc_score(self.y_test, self.predictions_proba)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_roc_curve","title":"get_roc_curve","text":"<pre><code>get_roc_curve()\n</code></pre> <p>Get the roc curve of the model.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_roc_curve(self):\n    \"\"\"Get the roc curve of the model.\"\"\"\n    return roc_curve(self.y_test, self.predictions_proba)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_violin_plot","title":"get_violin_plot","text":"<pre><code>get_violin_plot(max_display: int = DEFAULT_MAX_DISPLAY, class_index: int = -1)\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_violin_plot(self, max_display: int = DEFAULT_MAX_DISPLAY, class_index: int = -1):\n    return self.get_plot(\"violin\", max_display, class_index=class_index)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.get_waterfall_plot","title":"get_waterfall_plot","text":"<pre><code>get_waterfall_plot(max_display: int = DEFAULT_MAX_DISPLAY, index: int = 0, class_index: int = -1)\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def get_waterfall_plot(\n    self, max_display: int = DEFAULT_MAX_DISPLAY, index: int = 0, class_index: int = -1\n):\n    return self.get_plot(\"waterfall\", max_display, index=index, class_index=class_index)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.load_state","title":"load_state  <code>classmethod</code>","text":"<pre><code>load_state(file_path: str)\n</code></pre> <p>Loads the state of the class from a pkl file. Warning: Only use this method with trusted data sources as pickle can be unsafe.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>@classmethod\ndef load_state(cls, file_path: str):\n    \"\"\"Loads the state of the class from a pkl file.\n    Warning: Only use this method with trusted data sources as pickle can be unsafe.\n    \"\"\"\n    with Path(file_path).open(\"rb\") as f:\n        return pickle.load(f)  # noqa: S301\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.plot_confusion_matrix","title":"plot_confusion_matrix","text":"<pre><code>plot_confusion_matrix(plot_config: dict | None = None)\n</code></pre> <p>Plot confusion matrix with given configuration.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def plot_confusion_matrix(self, plot_config: dict | None = None):\n    \"\"\"Plot confusion matrix with given configuration.\"\"\"\n    from sklearn.metrics import ConfusionMatrixDisplay\n\n    config = {\n        \"include_values\": True,\n        \"cmap\": \"viridis\",\n        \"xticks_rotation\": \"horizontal\",\n        \"values_format\": None,\n        \"ax\": None,\n        \"colorbar\": True,\n        \"im_kw\": None,\n        \"text_kw\": None,\n        **(plot_config or {}),\n    }\n\n    cm = self.get_confusion_matrix()\n    ConfusionMatrixDisplay(cm).plot(**config)\n\n    if plot_config and plot_config.get(\"save_path\"):\n        plt.savefig(\n            Path(plot_config[\"save_path\"]) / plot_config[\"save_name\"],\n            format=plot_config.get(\"save_format\", \"png\"),\n            dpi=plot_config.get(\"save_dpi\", 300),\n            bbox_inches=\"tight\",\n        )\n\n    return plt.gcf()\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.save_state","title":"save_state","text":"<pre><code>save_state(file_path: str)\n</code></pre> <p>Saves the state of the class and its variables in a pkl file.</p> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def save_state(self, file_path: str):\n    \"\"\"Saves the state of the class and its variables in a pkl file.\"\"\"\n    with Path(file_path).open(\"wb\") as f:\n        pickle.dump(self, f)\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAI.validate_predict_proba","title":"validate_predict_proba","text":"<pre><code>validate_predict_proba() -&gt; bool\n</code></pre> Source code in <code>src/quoptuna/backend/xai/xai.py</code> <pre><code>def validate_predict_proba(self) -&gt; bool:\n    if not hasattr(self.model, \"predict_proba\"):\n        msg = \"Model does not have a predict_proba method\"\n        raise TypeError(msg)\n    return True\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAIConfig","title":"XAIConfig  <code>dataclass</code>","text":"<pre><code>XAIConfig(use_proba: bool = True, onsubset: bool = True, feature_names: list[str] | None = None, subset_size: int = DEFAULT_SUBSET_SIZE, max_display: int = DEFAULT_MAX_DISPLAY, data_key: str = DATA_KEY, x_test_key: str = 'x_test', y_test_key: str = 'y_test')\n</code></pre> ATTRIBUTE DESCRIPTION <code>data_key</code> <p> TYPE: <code>str</code> </p> <code>feature_names</code> <p> TYPE: <code>list[str] | None</code> </p> <code>max_display</code> <p> TYPE: <code>int</code> </p> <code>onsubset</code> <p> TYPE: <code>bool</code> </p> <code>subset_size</code> <p> TYPE: <code>int</code> </p> <code>use_proba</code> <p> TYPE: <code>bool</code> </p> <code>x_test_key</code> <p> TYPE: <code>str</code> </p> <code>y_test_key</code> <p> TYPE: <code>str</code> </p>"},{"location":"api_docs.html#quoptuna.XAIConfig.data_key","title":"data_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>data_key: str = DATA_KEY\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAIConfig.feature_names","title":"feature_names  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>feature_names: list[str] | None = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAIConfig.max_display","title":"max_display  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_display: int = DEFAULT_MAX_DISPLAY\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAIConfig.onsubset","title":"onsubset  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>onsubset: bool = True\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAIConfig.subset_size","title":"subset_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>subset_size: int = DEFAULT_SUBSET_SIZE\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAIConfig.use_proba","title":"use_proba  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>use_proba: bool = True\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAIConfig.x_test_key","title":"x_test_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>x_test_key: str = 'x_test'\n</code></pre>"},{"location":"api_docs.html#quoptuna.XAIConfig.y_test_key","title":"y_test_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>y_test_key: str = 'y_test'\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer","title":"Optimizer","text":"<pre><code>Optimizer(db_name: str, dataset_name: str = '', data: Optional[dict] = None, study_name: str = '')\n</code></pre> <p>Initialize the Optimizer class.</p> PARAMETER DESCRIPTION <p>The name of the database to be used for storing optimization results.</p> <p> TYPE: <code>str</code> </p> <p>The name of the dataset. If provided, the data will be loaded from a CSV file located in the 'notebook' directory. Defaults to an empty string.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <p>A dictionary containing training and testing data. If not provided, an empty dictionary will be used. Expected keys are 'train_x', 'test_x', 'train_y', and 'test_y'.</p> <p> TYPE: <code>Optional[dict]</code> DEFAULT: <code>None</code> </p> <p>The name of the study for Optuna. Defaults to an empty string.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> ATTRIBUTE DESCRIPTION <code>db_name</code> <p>The name of the database.</p> <p> </p> <code>dataset_name</code> <p>The name of the dataset.</p> <p> </p> <code>data_path</code> <p>The path to the dataset CSV file or an empty string if no dataset name is provided.</p> <p> </p> <code>data</code> <p>The data dictionary containing training and testing data.</p> <p> </p> <code>train_x</code> <p>The training features.</p> <p> </p> <code>test_x</code> <p>The testing features.</p> <p> </p> <code>train_y</code> <p>The training labels.</p> <p> </p> <code>test_y</code> <p>The testing labels.</p> <p> </p> <code>storage_location</code> <p>The storage location for the Optuna study.</p> <p> </p> <code>study_name</code> <p>The name of the Optuna study.</p> <p> </p> <code>study</code> <p>The Optuna study object.</p> <p> </p> METHOD DESCRIPTION <code>load_and_preprocess_data</code> <code>load_study</code> <code>log_user_attributes</code> <code>objective</code> <code>optimize</code> ATTRIBUTE DESCRIPTION <code>data</code> <p> </p> <code>data_path</code> <p> </p> <code>dataset_name</code> <p> </p> <code>db_name</code> <p> </p> <code>storage_location</code> <p> </p> <code>study</code> <p> </p> <code>study_name</code> <p> </p> <code>test_x</code> <p> </p> <code>test_y</code> <p> </p> <code>train_x</code> <p> </p> <code>train_y</code> <p> </p> Source code in <code>src/quoptuna/backend/tuners/optimizer.py</code> <pre><code>def __init__(\n    self,\n    db_name: str,\n    dataset_name: str = \"\",\n    data: Optional[dict] = None,  # noqa: FA100\n    study_name: str = \"\",\n):\n    \"\"\"Initialize the Optimizer class.\n\n    Args:\n        db_name: The name of the database to be used for storing optimization results.\n        dataset_name: The name of the dataset. If provided, the data will be loaded from a\n            CSV file located in the 'notebook' directory. Defaults to an empty string.\n        data: A dictionary containing training and testing data. If not provided, an empty\n            dictionary will be used. Expected keys are 'train_x', 'test_x', 'train_y', and 'test_y'.\n        study_name: The name of the study for Optuna. Defaults to an empty string.\n\n    Attributes:\n        db_name: The name of the database.\n        dataset_name: The name of the dataset.\n        data_path: The path to the dataset CSV file or an empty string if no dataset name is provided.\n        data: The data dictionary containing training and testing data.\n        train_x: The training features.\n        test_x: The testing features.\n        train_y: The training labels.\n        test_y: The testing labels.\n        storage_location: The storage location for the Optuna study.\n        study_name: The name of the Optuna study.\n        study: The Optuna study object.\n    \"\"\"\n    self.db_name = db_name\n    self.dataset_name = dataset_name\n    if len(self.dataset_name) &gt; 0:\n        self.data_path = f\"notebook/{self.dataset_name}.csv\"\n    else:\n        self.data_path = \"\"\n    self.data = data or {}  # Use an empty dictionary if no data is provided\n    self.train_x = self.data.get(\"train_x\")\n    self.test_x = self.data.get(\"test_x\")\n    self.train_y = self.data.get(\"train_y\")\n    self.test_y = self.data.get(\"test_y\")\n    self.data_path = f\"db/{self.db_name}.db\"\n    if not os.path.exists(\"db\"):  # noqa: PTH110\n        os.makedirs(\"db\")  # noqa: PTH103\n    self.storage_location = f\"sqlite:///{self.data_path}\"\n    self.study_name = study_name\n    self.study = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer(db_name)","title":"<code>db_name</code>","text":""},{"location":"api_docs.html#quoptuna.Optimizer(dataset_name)","title":"<code>dataset_name</code>","text":""},{"location":"api_docs.html#quoptuna.Optimizer(data)","title":"<code>data</code>","text":""},{"location":"api_docs.html#quoptuna.Optimizer(study_name)","title":"<code>study_name</code>","text":""},{"location":"api_docs.html#quoptuna.Optimizer.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data = data or {}\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.data_path","title":"data_path  <code>instance-attribute</code>","text":"<pre><code>data_path = f'db/{db_name}.db'\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.dataset_name","title":"dataset_name  <code>instance-attribute</code>","text":"<pre><code>dataset_name = dataset_name\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.db_name","title":"db_name  <code>instance-attribute</code>","text":"<pre><code>db_name = db_name\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.storage_location","title":"storage_location  <code>instance-attribute</code>","text":"<pre><code>storage_location = f'sqlite:///{data_path}'\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.study","title":"study  <code>instance-attribute</code>","text":"<pre><code>study = None\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.study_name","title":"study_name  <code>instance-attribute</code>","text":"<pre><code>study_name = study_name\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.test_x","title":"test_x  <code>instance-attribute</code>","text":"<pre><code>test_x = get('test_x')\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.test_y","title":"test_y  <code>instance-attribute</code>","text":"<pre><code>test_y = get('test_y')\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.train_x","title":"train_x  <code>instance-attribute</code>","text":"<pre><code>train_x = get('train_x')\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.train_y","title":"train_y  <code>instance-attribute</code>","text":"<pre><code>train_y = get('train_y')\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.load_and_preprocess_data","title":"load_and_preprocess_data","text":"<pre><code>load_and_preprocess_data()\n</code></pre> Source code in <code>src/quoptuna/backend/tuners/optimizer.py</code> <pre><code>def load_and_preprocess_data(self):\n    self.X, self.y = load_data(self.data_path)\n    self.train_x, self.test_x, self.train_y, self.test_y = preprocess_data(self.X, self.y)\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.load_study","title":"load_study","text":"<pre><code>load_study()\n</code></pre> Source code in <code>src/quoptuna/backend/tuners/optimizer.py</code> <pre><code>def load_study(self):\n    # load the study from the database\n    self.study = load_study(\n        storage=self.storage_location,\n        study_name=self.study_name,\n    )\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.log_user_attributes","title":"log_user_attributes","text":"<pre><code>log_user_attributes(model_type, eval_scores, trial)\n</code></pre> Source code in <code>src/quoptuna/backend/tuners/optimizer.py</code> <pre><code>def log_user_attributes(self, model_type, eval_scores, trial):\n    if model_type in [\"SVC\", \"SVClinear\", \"MLPClassifier\", \"Perceptron\"]:\n        trial.set_user_attr(\"Classical_accuracy\", eval_scores[\"accuracy\"])\n        trial.set_user_attr(\"Classical_f1_score\", eval_scores[\"f1_score\"])\n        trial.set_user_attr(\"Classical_score\", eval_scores[\"score\"])\n        trial.set_user_attr(\"Quantum_accuracy\", 0)\n        trial.set_user_attr(\"Quantum_f1_score\", 0)\n        trial.set_user_attr(\"Quantum_score\", 0)\n    else:\n        trial.set_user_attr(\"Quantum_accuracy\", eval_scores[\"accuracy\"])\n        trial.set_user_attr(\"Quantum_f1_score\", eval_scores[\"f1_score\"])\n        trial.set_user_attr(\"Quantum_score\", eval_scores[\"score\"])\n        trial.set_user_attr(\"Classical_accuracy\", 0)\n        trial.set_user_attr(\"Classical_f1_score\", 0)\n        trial.set_user_attr(\"Classical_score\", 0)\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.objective","title":"objective","text":"<pre><code>objective(trial: Trial)\n</code></pre> Source code in <code>src/quoptuna/backend/tuners/optimizer.py</code> <pre><code>def objective(self, trial: Trial):\n    try:\n        # Define the hyperparameter search space\n        params = {\n            \"max_vmap\": trial.suggest_categorical(\"max_vmap\", [1]),\n            \"batch_size\": trial.suggest_categorical(\"batch_size\", [32]),\n            \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.001, 0.01, 0.1]),\n            \"n_input_copies\": trial.suggest_categorical(\"n_input_copies\", [1, 2, 3]),\n            \"n_layers\": trial.suggest_categorical(\"n_layers\", [1, 5, 10]),\n            \"observable_type\": trial.suggest_categorical(\n                \"observable_type\", [\"single\", \"half\", \"full\"]\n            ),\n            \"repeats\": trial.suggest_categorical(\"repeats\", [1, 5, 10]),\n            \"C\": trial.suggest_categorical(\"C\", [0.1, 1, 10, 100]),\n            \"gamma_factor\": trial.suggest_categorical(\"gamma_factor\", [0.1, 1, 10]),\n            \"trotter_steps\": trial.suggest_categorical(\"trotter_steps\", [1, 3, 5]),\n            \"t\": trial.suggest_categorical(\"t\", [0.01, 0.1, 1.0]),\n            \"n_qfeatures\": trial.suggest_categorical(\"n_qfeatures\", [\"full\", \"half\"]),\n            \"n_episodes\": trial.suggest_categorical(\"n_episodes\", [10, 100, 500, 2000]),\n            \"visible_qubits\": trial.suggest_categorical(\n                \"visible_qubits\", [\"single\", \"half\", \"full\"]\n            ),\n            \"temperature\": trial.suggest_categorical(\"temperature\", [1, 10, 100]),\n            \"encoding_layers\": trial.suggest_categorical(\"encoding_layers\", [1, 3, 5, 10]),\n            \"degree\": trial.suggest_categorical(\"degree\", [2, 3, 4]),\n            \"n_qchannels\": trial.suggest_categorical(\"n_qchannels\", [1, 5, 10]),\n            \"qkernel_shape\": trial.suggest_categorical(\"qkernel_shape\", [2, 3]),\n            \"kernel_shape\": trial.suggest_categorical(\"kernel_shape\", [2, 3, 5]),\n            \"filter_name\": trial.suggest_categorical(\n                \"filter_name\", [\"edge_detect\", \"smooth\", \"sharpen\"]\n            ),\n            \"gamma\": trial.suggest_categorical(\"gamma\", [0.001, 0.01, 0.1, 1]),\n            \"alpha\": trial.suggest_categorical(\"alpha\", [0.01, 0.001, 0.0001]),\n            \"hidden_layer_sizes\": trial.suggest_categorical(\n                \"hidden_layer_sizes\", [\"[100,)\", \"(10, 10, 10, 10)\", \"(50, 10, 5)\"]\n            ),\n            \"eta0\": trial.suggest_categorical(\"eta0\", [0.1, 1, 10]),\n        }\n\n        model_type = trial.suggest_categorical(\n            \"model_type\",\n            [\n                \"CircuitCentricClassifier\",\n                \"DataReuploadingClassifier\",\n                \"DataReuploadingClassifierSeparable\",\n                \"DressedQuantumCircuitClassifier\",\n                \"DressedQuantumCircuitClassifierSeparable\",\n                \"ProjectedQuantumKernel\",\n                \"QuantumKitchenSinks\",\n                \"QuantumMetricLearner\",\n                \"TreeTensorClassifier\",\n                \"SeparableVariationalClassifier\",\n                \"SeparableKernelClassifier\",\n                \"SVC\",\n                \"SVClinear\",\n                \"MLPClassifier\",\n                \"Perceptron\",\n            ],\n        )\n\n        model = create_model(model_type, **params)\n\n        model.fit(self.train_x, self.train_y)\n        score = model.score(self.test_x, self.test_y)\n\n        f_score_ = f1_score(self.test_y, model.predict(self.test_x))\n        acc_ = accuracy_score(self.test_y, model.predict(self.test_x))\n\n        self.log_user_attributes(\n            model_type,\n            {\"accuracy\": acc_, \"f1_score\": f_score_, \"score\": score},\n            trial,\n        )\n\n        return f_score_  # noqa: TRY300\n    except Exception:\n        import logging\n\n        logging.exception(\"An error occurred\")  # Use logging instead of print\n        return 0\n</code></pre>"},{"location":"api_docs.html#quoptuna.Optimizer.optimize","title":"optimize","text":"<pre><code>optimize(n_trials=100)\n</code></pre> Source code in <code>src/quoptuna/backend/tuners/optimizer.py</code> <pre><code>def optimize(self, n_trials=100):\n    if (\n        self.train_x is None\n        or self.test_x is None\n        or self.train_y is None\n        or self.test_y is None\n    ):\n        self.load_and_preprocess_data()\n    # database  stored in a db folder \"db\"\n\n    # sqllite database\n\n    study = create_study(\n        storage=self.storage_location,\n        sampler=TPESampler(),\n        directions=[\"maximize\"],\n        study_name=self.study_name,\n    )\n    self.study = study\n    study.optimize(self.objective, n_trials=n_trials)\n    return study, study.best_trials\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation","title":"DataPreparation","text":"<pre><code>DataPreparation(dataset: DataSet | None = None, file_path: str | None = None, x_cols: list[str] | None = None, y_col: str | None = None, scaler=None)\n</code></pre> METHOD DESCRIPTION <code>create_dataset</code> <p>Creates a dataset from raw data.</p> <code>get_data</code> <code>prepare_data</code> <p>Selects columns and preprocesses the data.</p> <code>prepare_data_dict</code> <code>preprocess</code> <p>Preprocess the features and target.</p> <code>read_csv</code> <p>Reads a CSV file and returns a raw dataset.</p> <code>select_columns</code> <p>Selects specified columns and splits the dataset into features and target.</p> <code>set_x_cols</code> <code>set_y_col</code> <code>update_column_names</code> <p>Update column names in x_cols if they are single length after conversion to string.</p> ATTRIBUTE DESCRIPTION <code>dataset</code> <p> </p> <code>scaler</code> <p> </p> <code>x_cols</code> <p> </p> <code>y_col</code> <p> </p> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def __init__(\n    self,\n    dataset: DataSet | None = None,\n    file_path: str | None = None,\n    x_cols: list[str] | None = None,\n    y_col: str | None = None,\n    scaler=None,\n):\n    self.x_cols = x_cols\n    self.y_col = y_col\n    self.scaler = scaler or StandardScaler()\n    if dataset is not None:\n        x = self.update_column_names(dataset.get(\"x\"))\n        self.set_x_cols(x.columns)\n        self.dataset = {\"x\": x, \"y\": dataset.get(\"y\")}\n    elif file_path is not None:\n        if x_cols is None or y_col is None:\n            msg = \"x_cols and y_col must be provided when file_path is used\"\n            raise ValueError(msg)\n        self.dataset = self.create_dataset(self.read_csv(file_path), x_cols, y_col)\n    else:\n        msg = \"Either dataset or file_path must be provided\"\n        raise ValueError(msg)\n    self.x_train, self.x_test, self.y_train, self.y_test = self.prepare_data()\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.dataset","title":"dataset  <code>instance-attribute</code>","text":"<pre><code>dataset = {'x': x, 'y': get('y')}\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.scaler","title":"scaler  <code>instance-attribute</code>","text":"<pre><code>scaler = scaler or StandardScaler()\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.x_cols","title":"x_cols  <code>instance-attribute</code>","text":"<pre><code>x_cols = x_cols\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.y_col","title":"y_col  <code>instance-attribute</code>","text":"<pre><code>y_col = y_col\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.create_dataset","title":"create_dataset","text":"<pre><code>create_dataset(raw_data: DataFrame, x_cols: list[str], y_col: str) -&gt; DataSet\n</code></pre> <p>Creates a dataset from raw data.</p> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def create_dataset(self, raw_data: pd.DataFrame, x_cols: list[str], y_col: str) -&gt; DataSet:\n    \"\"\"Creates a dataset from raw data.\"\"\"\n    x = raw_data[x_cols]\n    y = raw_data[y_col]\n    x = self.update_column_names(x)\n    self.set_x_cols(x.columns)\n    return {\"x\": x, \"y\": y}\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.get_data","title":"get_data","text":"<pre><code>get_data(output_type: Literal['1', '2'] = '1')\n</code></pre> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def get_data(self, output_type: Literal[\"1\", \"2\"] = \"1\"):\n    if output_type == \"1\":\n        return {\n            \"x_train\": self.x_train,\n            \"x_test\": self.x_test,\n            \"y_train\": self.y_train,\n            \"y_test\": self.y_test,\n        }\n    if output_type == \"2\":\n        return {\n            \"train_x\": self.x_train,\n            \"train_y\": self.y_train,\n            \"test_x\": self.x_test,\n            \"test_y\": self.y_test,\n        }\n    return None\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.prepare_data","title":"prepare_data","text":"<pre><code>prepare_data()\n</code></pre> <p>Selects columns and preprocesses the data.</p> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def prepare_data(self):\n    \"\"\"Selects columns and preprocesses the data.\"\"\"\n    if self.x_cols is None or self.y_col is None:\n        msg = \"x_cols and y_col must be provided\"\n        raise ValueError(msg)\n    x, y = self.select_columns()\n    return self.preprocess(x, y)\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.prepare_data_dict","title":"prepare_data_dict","text":"<pre><code>prepare_data_dict(x_train, y_train, x_test, y_test)\n</code></pre> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def prepare_data_dict(self, x_train, y_train, x_test, y_test):\n    return {\"x_train\": x_train, \"x_test\": x_test, \"y_train\": y_train, \"y_test\": y_test}\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.preprocess","title":"preprocess","text":"<pre><code>preprocess(x: DataFrame, y: Series, train_size: float = 0.75)\n</code></pre> <p>Preprocess the features and target.</p> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def preprocess(self, x: pd.DataFrame, y: pd.Series, train_size: float = 0.75):\n    \"\"\"Preprocess the features and target.\"\"\"\n    x = pd.DataFrame(self.scaler.fit_transform(x), columns=x.columns)\n    classes = np.unique(y)\n    y = pd.DataFrame(\n        np.where(y == classes[0], 1, -1),\n        columns=[self.y_col] if not isinstance(self.y_col, list) else self.y_col,\n    )\n    return train_test_split(x, y, train_size=train_size, random_state=42)\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.read_csv","title":"read_csv  <code>staticmethod</code>","text":"<pre><code>read_csv(file_path: str) -&gt; DataFrame\n</code></pre> <p>Reads a CSV file and returns a raw dataset.</p> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>@staticmethod\ndef read_csv(file_path: str) -&gt; pd.DataFrame:\n    \"\"\"Reads a CSV file and returns a raw dataset.\"\"\"\n    return pd.read_csv(file_path)\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.select_columns","title":"select_columns","text":"<pre><code>select_columns()\n</code></pre> <p>Selects specified columns and splits the dataset into features and target.</p> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def select_columns(self):\n    \"\"\"Selects specified columns and splits the dataset into features and target.\"\"\"\n    if self.x_cols is None or self.y_col is None:\n        msg = \"x_cols and y_col must be provided\"\n        raise ValueError(msg)\n    x = self.dataset.get(\"x\")\n    y = self.dataset.get(\"y\")\n    return x, y\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.set_x_cols","title":"set_x_cols","text":"<pre><code>set_x_cols(x_cols: list[str])\n</code></pre> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def set_x_cols(self, x_cols: list[str]):\n    self.x_cols = x_cols\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.set_y_col","title":"set_y_col","text":"<pre><code>set_y_col(y_col: str)\n</code></pre> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def set_y_col(self, y_col: str):\n    self.y_col = y_col\n</code></pre>"},{"location":"api_docs.html#quoptuna.DataPreparation.update_column_names","title":"update_column_names","text":"<pre><code>update_column_names(dataframe: DataFrame | None = None)\n</code></pre> <p>Update column names in x_cols if they are single length after conversion to string. Also updates the corresponding DataFrame if provided.</p> Source code in <code>src/quoptuna/backend/utils/data_utils/prepare.py</code> <pre><code>def update_column_names(self, dataframe: pd.DataFrame | None = None):\n    \"\"\"Update column names in x_cols if they are single length after conversion to string.\n    Also updates the corresponding DataFrame if provided.\n    \"\"\"\n    if self.x_cols is not None:\n        for i, col in enumerate(self.x_cols):\n            if len(str(col)) == 1:\n                self.x_cols[i] = f\"feat: {col}\"\n                if dataframe is not None and col in dataframe.columns:\n                    dataframe = dataframe.rename(columns={col: f\"feat: {col}\"})\n    return dataframe\n</code></pre>"},{"location":"api_docs.html#quoptuna.create_model","title":"create_model","text":"<pre><code>create_model(model_type, **kwargs)\n</code></pre> Source code in <code>src/quoptuna/backend/models.py</code> <pre><code>def create_model(model_type, **kwargs):\n    model_constructors = {\n        \"CircuitCentricClassifier\": (\n            CircuitCentricClassifier,\n            [\"max_vmap\", \"batch_size\", \"learning_rate\", \"n_input_copies\", \"n_layers\"],\n        ),\n        \"DataReuploadingClassifier\": (\n            DataReuploadingClassifier,\n            [\"max_vmap\", \"batch_size\", \"learning_rate\", \"n_layers\", \"observable_type\"],\n        ),\n        \"DataReuploadingClassifierSeparable\": (\n            DataReuploadingClassifierSeparable,\n            [\"max_vmap\", \"batch_size\", \"learning_rate\", \"n_layers\", \"observable_type\"],\n        ),\n        \"DressedQuantumCircuitClassifier\": (\n            DressedQuantumCircuitClassifier,\n            [\"max_vmap\", \"batch_size\", \"learning_rate\", \"n_layers\"],\n        ),\n        \"DressedQuantumCircuitClassifierSeparable\": (\n            DressedQuantumCircuitClassifierSeparable,\n            [\"max_vmap\", \"batch_size\", \"learning_rate\", \"n_layers\"],\n        ),\n        \"IQPKernelClassifier\": (IQPKernelClassifier, [\"max_vmap\", \"repeats\", \"C\"]),\n        \"ProjectedQuantumKernel\": (\n            ProjectedQuantumKernel,\n            [\"max_vmap\", \"gamma_factor\", \"C\", \"trotter_steps\", \"t\"],\n        ),\n        \"QuantumKitchenSinks\": (\n            QuantumKitchenSinks,\n            [\"max_vmap\", \"n_qfeatures\", \"n_episodes\"],\n        ),\n        \"QuantumMetricLearner\": (\n            QuantumMetricLearner,\n            [\"max_vmap\", \"batch_size\", \"learning_rate\", \"n_layers\"],\n        ),\n        \"QuantumBoltzmannMachine\": (\n            QuantumBoltzmannMachine,\n            [\n                \"max_vmap\",\n                \"batch_size\",\n                \"learning_rate\",\n                \"visible_qubits\",\n                \"temperature\",\n            ],\n        ),\n        \"QuantumBoltzmannMachineSeparable\": (\n            QuantumBoltzmannMachineSeparable,\n            [\n                \"max_vmap\",\n                \"batch_size\",\n                \"learning_rate\",\n                \"visible_qubits\",\n                \"temperature\",\n            ],\n        ),\n        \"TreeTensorClassifier\": (\n            TreeTensorClassifier,\n            [\"max_vmap\", \"batch_size\", \"learning_rate\"],\n        ),\n        \"QuanvolutionalNeuralNetwork\": (\n            QuanvolutionalNeuralNetwork,\n            [\n                \"max_vmap\",\n                \"batch_size\",\n                \"learning_rate\",\n                \"n_qchannels\",\n                \"qkernel_shape\",\n                \"kernel_shape\",\n            ],\n        ),\n        \"WeiNet\": (WeiNet, [\"max_vmap\", \"batch_size\", \"learning_rate\", \"filter_name\"]),\n        \"SeparableVariationalClassifier\": (\n            SeparableVariationalClassifier,\n            [\"batch_size\", \"learning_rate\", \"encoding_layers\"],\n        ),\n        \"SeparableKernelClassifier\": (\n            SeparableKernelClassifier,\n            [\"C\", \"encoding_layers\"],\n        ),\n        \"ConvolutionalNeuralNetwork\": (\n            ConvolutionalNeuralNetwork,\n            [\"batch_size\", \"learning_rate\", \"kernel_shape\"],\n        ),\n        \"SVC\": (SVC, [\"gamma\", \"C\"]),\n        \"SVClinear\": (LinearSVC, [\"C\"]),\n        \"MLPClassifier\": (\n            MLPClassifier,\n            [\"batch_size\", \"learning_rate\", \"hidden_layer_sizes\", \"alpha\"],\n        ),\n        \"Perceptron\": (Perceptron, [\"eta0\"]),\n    }\n\n    if model_type not in model_constructors:\n        raise UnknownModelTypeError(model_type)\n\n    model_class, param_keys = model_constructors[model_type]\n    params = {key: kwargs.get(key) for key in param_keys}\n\n    if model_type == \"MLPClassifier\":\n        params[\"hidden_layer_sizes\"] = ast.literal_eval(params[\"hidden_layer_sizes\"])\n\n    return model_class(**params)\n</code></pre>"},{"location":"api_reference.html","title":"API Reference","text":""},{"location":"api_reference.html#api-reference","title":"API Reference","text":""},{"location":"api_reference.html#overview","title":"Overview","text":"<p>QuOptuna provides a comprehensive Python API for quantum-enhanced machine learning optimization. This reference covers the main classes and functions available for programmatic use.</p>"},{"location":"api_reference.html#core-classes","title":"Core Classes","text":""},{"location":"api_reference.html#datapreparation","title":"DataPreparation","text":"<p>Handles data loading, preprocessing, and splitting.</p> <pre><code>from quoptuna import DataPreparation\n\ndata_prep = DataPreparation(\n    file_path=\"path/to/data.csv\",\n    x_cols=[\"feature1\", \"feature2\", \"feature3\"],\n    y_col=\"target\"\n)\n\n# Get preprocessed data\ndata_dict = data_prep.get_data(output_type=\"2\")\n</code></pre> <p>Parameters: - <code>file_path</code> (str): Path to the CSV data file - <code>x_cols</code> (list): List of feature column names - <code>y_col</code> (str): Target column name - <code>test_size</code> (float, optional): Proportion of data for testing (default: 0.25) - <code>random_state</code> (int, optional): Random seed for reproducibility</p> <p>Methods:</p>"},{"location":"api_reference.html#get_dataoutput_type2","title":"<code>get_data(output_type=\"2\")</code>","text":"<p>Returns preprocessed data dictionary.</p> <p>Parameters: - <code>output_type</code> (str): Format of output   - <code>\"1\"</code>: Returns pandas DataFrames   - <code>\"2\"</code>: Returns numpy arrays (recommended for optimization)</p> <p>Returns: - dict: Dictionary with keys <code>train_x</code>, <code>test_x</code>, <code>train_y</code>, <code>test_y</code></p>"},{"location":"api_reference.html#optimizer","title":"Optimizer","text":"<p>Manages hyperparameter optimization using Optuna.</p> <pre><code>from quoptuna import Optimizer\n\noptimizer = Optimizer(\n    db_name=\"my_experiment\",\n    study_name=\"trial_001\",\n    data=data_dict\n)\n\n# Run optimization\nstudy, best_trials = optimizer.optimize(n_trials=100)\n</code></pre> <p>Parameters: - <code>db_name</code> (str): Database name for storing results - <code>study_name</code> (str): Unique study identifier - <code>data</code> (dict): Data dictionary from DataPreparation - <code>dataset_name</code> (str, optional): Human-readable dataset name</p> <p>Attributes: - <code>storage_location</code> (str): SQLite database URI - <code>study</code> (optuna.Study): Optuna study object - <code>best_trials</code> (list): List of best performing trials</p> <p>Methods:</p>"},{"location":"api_reference.html#optimizen_trials100-timeoutnone","title":"<code>optimize(n_trials=100, timeout=None)</code>","text":"<p>Run hyperparameter optimization.</p> <p>Parameters: - <code>n_trials</code> (int): Number of optimization trials - <code>timeout</code> (int, optional): Maximum optimization time in seconds</p> <p>Returns: - <code>study</code> (optuna.Study): Completed study - <code>best_trials</code> (list): List of Pareto-optimal trials</p>"},{"location":"api_reference.html#load_study","title":"<code>load_study()</code>","text":"<p>Load previously saved study from database.</p> <p>Returns: - <code>study</code> (optuna.Study): Loaded study object</p>"},{"location":"api_reference.html#model-creation","title":"Model Creation","text":"<p>Create models with optimized hyperparameters.</p> <pre><code>from quoptuna.backend.models import create_model\n\n# From trial parameters\nmodel = create_model(**trial.params)\n\n# Or specify directly\nmodel = create_model(\n    model_type=\"DataReuploadingClassifier\",\n    n_layers=10,\n    learning_rate=0.1,\n    batch_size=32\n)\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions\npredictions = model.predict(X_test)\n</code></pre> <p>Supported Models:</p>"},{"location":"api_reference.html#quantum-models","title":"Quantum Models","text":"<p>DataReuploadingClassifier - <code>n_layers</code> (int): Number of quantum layers - <code>learning_rate</code> (float): Learning rate for optimization - <code>batch_size</code> (int): Batch size for training - <code>n_input_copies</code> (int): Number of data reuploads - <code>observable_type</code> (str): Type of observable (\"all\" or \"half\")</p> <p>CircuitCentricClassifier - <code>n_layers</code> (int): Circuit depth - <code>learning_rate</code> (float): Learning rate - <code>n_qubits</code> (int): Number of qubits</p> <p>QuantumKitchenSinks - <code>n_episodes</code> (int): Number of training episodes - <code>learning_rate</code> (float): Learning rate - <code>gamma</code> (float): Kernel parameter</p>"},{"location":"api_reference.html#classical-models","title":"Classical Models","text":"<p>SVC (Support Vector Classifier) - <code>C</code> (float): Regularization parameter - <code>gamma</code> (str or float): Kernel coefficient - <code>kernel</code> (str): Kernel type</p> <p>MLPClassifier - <code>hidden_layer_sizes</code> (tuple): Hidden layer configuration - <code>learning_rate</code> (str): Learning rate schedule - <code>alpha</code> (float): L2 regularization parameter</p>"},{"location":"api_reference.html#xai-explainable-ai","title":"XAI (Explainable AI)","text":"<p>Generate SHAP explanations and visualizations.</p> <pre><code>from quoptuna import XAI\nfrom quoptuna.backend.xai.xai import XAIConfig\n\n# Configure XAI\nconfig = XAIConfig(\n    use_proba=True,\n    onsubset=True,\n    subset_size=50\n)\n\n# Create XAI instance\nxai = XAI(\n    model=trained_model,\n    data=data_dict,\n    config=config\n)\n\n# Get evaluation report\nreport = xai.get_report()\n</code></pre> <p>XAIConfig Parameters: - <code>use_proba</code> (bool): Use probability predictions - <code>onsubset</code> (bool): Use subset of data - <code>subset_size</code> (int): Size of subset</p> <p>XAI Methods:</p>"},{"location":"api_reference.html#get_report","title":"<code>get_report()</code>","text":"<p>Generate classification report.</p> <p>Returns: - dict: Contains confusion matrix, classification report, and ROC curve data</p>"},{"location":"api_reference.html#get_plotplot_type-kwargs","title":"<code>get_plot(plot_type, **kwargs)</code>","text":"<p>Generate SHAP visualization.</p> <p>Parameters: - <code>plot_type</code> (str): Type of plot   - <code>\"bar\"</code>: Feature importance bar plot   - <code>\"beeswarm\"</code>: SHAP value distribution   - <code>\"violin\"</code>: Violin plot of SHAP values   - <code>\"heatmap\"</code>: Instance-level SHAP heatmap   - <code>\"waterfall\"</code>: Individual prediction explanation - <code>max_display</code> (int): Maximum features to display - <code>class_index</code> (int): Class to explain (for binary: 0 or 1) - <code>index</code> (int): Sample index (for waterfall plot) - <code>save_config</code> (dict, optional): Configuration for saving plot</p> <p>Returns: - str: Base64 encoded image</p>"},{"location":"api_reference.html#plot_confusion_matrix","title":"<code>plot_confusion_matrix()</code>","text":"<p>Generate confusion matrix plot.</p> <p>Returns: - matplotlib.figure.Figure: Confusion matrix figure</p>"},{"location":"api_reference.html#generate_report_with_langchainprovider-api_key-model_name-dataset_infonone","title":"<code>generate_report_with_langchain(provider, api_key, model_name, dataset_info=None)</code>","text":"<p>Generate AI-powered analysis report.</p> <p>Parameters: - <code>provider</code> (str): LLM provider (\"google\", \"openai\", \"anthropic\") - <code>api_key</code> (str): API key for the provider - <code>model_name</code> (str): Model identifier - <code>dataset_info</code> (dict, optional): Dataset metadata</p> <p>Returns: - str: Markdown formatted report</p>"},{"location":"api_reference.html#utility-functions","title":"Utility Functions","text":""},{"location":"api_reference.html#mock_csv_data","title":"mock_csv_data","text":"<p>Save DataFrame to CSV file.</p> <pre><code>from quoptuna.backend.utils.data_utils.data import mock_csv_data\n\nfile_path = mock_csv_data(\n    dataframe,\n    tmp_path=\"data\",\n    file_name=\"my_dataset\"\n)\n</code></pre> <p>Parameters: - <code>dataframe</code> (pd.DataFrame): Data to save - <code>tmp_path</code> (str): Directory path - <code>file_name</code> (str): File name (without .csv extension)</p> <p>Returns: - str: Full path to saved file</p>"},{"location":"api_reference.html#complete-example","title":"Complete Example","text":"<p>Here's a complete example workflow:</p> <pre><code>import pandas as pd\nfrom ucimlrepo import fetch_ucirepo\nfrom quoptuna import DataPreparation, Optimizer, XAI\nfrom quoptuna.backend.models import create_model\nfrom quoptuna.backend.xai.xai import XAIConfig\nfrom quoptuna.backend.utils.data_utils.data import mock_csv_data\n\n# 1. Load dataset\ndataset = fetch_ucirepo(id=143)  # Statlog dataset\nX = dataset.data.features\ny = dataset.data.targets\ndf = pd.concat([X, y], axis=1)\n\n# 2. Prepare data\ndf[\"target\"] = df[\"A15\"].replace({0: -1, 1: 1})\ndf = df.drop(columns=[\"A15\"])\ndf = df.dropna()\n\n# 3. Save to file\nfile_path = mock_csv_data(df, tmp_path=\"data\", file_name=\"Statlog\")\n\n# 4. Prepare for training\ndata_prep = DataPreparation(\n    file_path=file_path,\n    x_cols=list(df.columns.difference([\"target\"])),\n    y_col=\"target\"\n)\ndata_dict = data_prep.get_data(output_type=\"2\")\n\n# Convert to numpy arrays\ndata_dict[\"train_x\"] = data_dict[\"train_x\"].values\ndata_dict[\"test_x\"] = data_dict[\"test_x\"].values\ndata_dict[\"train_y\"] = data_dict[\"train_y\"].values\ndata_dict[\"test_y\"] = data_dict[\"test_y\"].values\n\n# 5. Run optimization\noptimizer = Optimizer(\n    db_name=\"Statlog\",\n    study_name=\"Statlog\",\n    data=data_dict\n)\nstudy, best_trials = optimizer.optimize(n_trials=100)\n\n# 6. Train best model\nbest_trial = best_trials[0]\nmodel = create_model(**best_trial.params)\nmodel.fit(data_dict[\"train_x\"], data_dict[\"train_y\"])\n\n# 7. SHAP analysis\nconfig = XAIConfig(use_proba=True, onsubset=True, subset_size=50)\nxai = XAI(model=model, data=data_dict, config=config)\n\n# 8. Generate visualizations\nbar_plot = xai.get_plot(\"bar\", max_display=10, class_index=1)\nbeeswarm_plot = xai.get_plot(\"beeswarm\", max_display=10, class_index=1)\n\n# 9. Generate report\nreport = xai.generate_report_with_langchain(\n    provider=\"google\",\n    api_key=\"your-api-key\",\n    model_name=\"models/gemini-2.0-flash-exp\",\n    dataset_info={\n        \"Name\": \"Statlog Credit Approval\",\n        \"URL\": \"https://archive.ics.uci.edu/dataset/143\",\n        \"Description\": \"Credit card application dataset\"\n    }\n)\n\nprint(report)\n</code></pre>"},{"location":"api_reference.html#data-format-requirements","title":"Data Format Requirements","text":""},{"location":"api_reference.html#input-data","title":"Input Data","text":"<p>CSV Format: - Must have header row with column names - Target column should contain binary values - Features can be numeric or categorical - Missing values will be removed</p> <p>Target Encoding: - Binary classification: Must use <code>-1</code> and <code>1</code> - QuOptuna does not currently support multi-class classification</p>"},{"location":"api_reference.html#data-dictionary-format","title":"Data Dictionary Format","text":"<p>After preprocessing, data should be in this format:</p> <pre><code>data_dict = {\n    \"train_x\": np.ndarray,  # Shape: (n_train_samples, n_features)\n    \"test_x\": np.ndarray,   # Shape: (n_test_samples, n_features)\n    \"train_y\": np.ndarray,  # Shape: (n_train_samples,)\n    \"test_y\": np.ndarray    # Shape: (n_test_samples,)\n}\n</code></pre>"},{"location":"api_reference.html#advanced-usage","title":"Advanced Usage","text":""},{"location":"api_reference.html#custom-optimization-objectives","title":"Custom Optimization Objectives","text":"<p>You can customize the optimization objective:</p> <pre><code>import optuna\n\ndef custom_objective(trial):\n    # Define your custom objective\n    params = {\n        \"model_type\": trial.suggest_categorical(\"model_type\", [\"SVC\", \"MLPClassifier\"]),\n        \"C\": trial.suggest_float(\"C\", 0.1, 10.0)\n    }\n\n    model = create_model(**params)\n    model.fit(train_x, train_y)\n\n    # Return custom metric\n    return custom_metric(model, test_x, test_y)\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(custom_objective, n_trials=100)\n</code></pre>"},{"location":"api_reference.html#parallel-optimization","title":"Parallel Optimization","text":"<p>Run multiple trials in parallel:</p> <pre><code>optimizer = Optimizer(db_name=\"my_db\", study_name=\"my_study\", data=data_dict)\n\n# Use n_jobs for parallel execution\nstudy, best_trials = optimizer.optimize(\n    n_trials=100,\n    n_jobs=4  # Run 4 trials in parallel\n)\n</code></pre>"},{"location":"api_reference.html#saving-and-loading-models","title":"Saving and Loading Models","text":"<pre><code>import joblib\n\n# Save model\njoblib.dump(model, \"model.pkl\")\n\n# Load model\nloaded_model = joblib.load(\"model.pkl\")\n</code></pre>"},{"location":"api_reference.html#error-handling","title":"Error Handling","text":"<p>Common errors and solutions:</p> <pre><code>try:\n    optimizer.optimize(n_trials=100)\nexcept ValueError as e:\n    # Handle data validation errors\n    print(f\"Data error: {e}\")\nexcept RuntimeError as e:\n    # Handle optimization errors\n    print(f\"Optimization error: {e}\")\nexcept Exception as e:\n    # Handle unexpected errors\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"api_reference.html#performance-tips","title":"Performance Tips","text":"<ol> <li>Use Subsets for SHAP: Analyze 50-100 samples for faster computation</li> <li>Increase Trials Gradually: Start with 50 trials, increase as needed</li> <li>Use Caching: Reuse loaded studies when possible</li> <li>Monitor Memory: Large datasets may require subset analysis</li> <li>Parallel Processing: Use <code>n_jobs</code> parameter for faster optimization</li> </ol>"},{"location":"api_reference.html#see-also","title":"See Also","text":"<ul> <li>User Guide - Step-by-step usage instructions</li> <li>Examples - Common use cases and tutorials</li> <li>GitHub Repository - Source code and issues</li> </ul>"},{"location":"changelog.html","title":"Changelog","text":""},{"location":"changelog.html#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog.html#unreleased","title":"Unreleased","text":""},{"location":"examples.html","title":"Examples","text":""},{"location":"examples.html#examples","title":"Examples","text":""},{"location":"examples.html#introduction","title":"Introduction","text":"<p>This page provides practical examples for common QuOptuna use cases. Each example includes complete, runnable code.</p>"},{"location":"examples.html#table-of-contents","title":"Table of Contents","text":"<ol> <li>Basic Workflow</li> <li>UCI Dataset Analysis</li> <li>Custom Dataset</li> <li>SHAP Analysis</li> <li>Comparing Models</li> <li>Report Generation</li> <li>Batch Processing</li> </ol>"},{"location":"examples.html#basic-workflow","title":"Basic Workflow","text":"<p>Complete workflow from data loading to SHAP analysis:</p> <pre><code>from quoptuna import DataPreparation, Optimizer, XAI\nfrom quoptuna.backend.models import create_model\nfrom quoptuna.backend.xai.xai import XAIConfig\nfrom quoptuna.backend.utils.data_utils.data import mock_csv_data\nimport pandas as pd\n\n# Load your data\ndf = pd.read_csv(\"your_data.csv\")\n\n# Ensure target is -1 and 1\ndf[\"target\"] = df[\"target\"].replace({0: -1, 1: 1})\n\n# Save to file\nfile_path = mock_csv_data(df, tmp_path=\"data\", file_name=\"my_data\")\n\n# Prepare data\ndata_prep = DataPreparation(\n    file_path=file_path,\n    x_cols=[col for col in df.columns if col != \"target\"],\n    y_col=\"target\"\n)\ndata_dict = data_prep.get_data(output_type=\"2\")\n\n# Convert to numpy\nfor key in [\"train_x\", \"test_x\", \"train_y\", \"test_y\"]:\n    data_dict[key] = data_dict[key].values\n\n# Optimize\noptimizer = Optimizer(db_name=\"my_experiment\", study_name=\"run_1\", data=data_dict)\nstudy, best_trials = optimizer.optimize(n_trials=50)\n\n# Train best model\nbest_model = create_model(**best_trials[0].params)\nbest_model.fit(data_dict[\"train_x\"], data_dict[\"train_y\"])\n\n# SHAP analysis\nxai = XAI(\n    model=best_model,\n    data=data_dict,\n    config=XAIConfig(use_proba=True, onsubset=True, subset_size=50)\n)\n\n# Generate plots\nbar_plot = xai.get_plot(\"bar\", max_display=10, class_index=1)\nprint(\"Analysis complete!\")\n</code></pre>"},{"location":"examples.html#uci-dataset-analysis","title":"UCI Dataset Analysis","text":"<p>Working with UCI ML Repository datasets:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nfrom quoptuna import DataPreparation, Optimizer\nfrom quoptuna.backend.utils.data_utils.data import mock_csv_data\nimport pandas as pd\n\n# Fetch dataset from UCI\ndataset = fetch_ucirepo(id=143)  # Statlog Credit Approval\n\n# Get metadata\nprint(\"Dataset:\", dataset.metadata[\"name\"])\nprint(\"Instances:\", dataset.metadata[\"num_instances\"])\nprint(\"Features:\", dataset.metadata[\"num_features\"])\n\n# Prepare data\nX = dataset.data.features\ny = dataset.data.targets\ndf = pd.concat([X, y], axis=1)\n\n# Transform target\ntarget_col = dataset.metadata[\"target_col\"][0]\ndf[\"target\"] = df[target_col].replace({0: -1, 1: 1})\ndf = df.drop(columns=[target_col])\ndf = df.dropna()\n\n# Save and prepare\nfile_path = mock_csv_data(df, tmp_path=\"data\", file_name=\"Statlog\")\n\ndata_prep = DataPreparation(\n    file_path=file_path,\n    x_cols=list(df.columns.difference([\"target\"])),\n    y_col=\"target\"\n)\ndata_dict = data_prep.get_data(output_type=\"2\")\n\n# Convert to numpy\nfor key in data_dict.keys():\n    data_dict[key] = data_dict[key].values\n\n# Run optimization\noptimizer = Optimizer(db_name=\"Statlog\", study_name=\"Statlog\", data=data_dict)\nstudy, best_trials = optimizer.optimize(n_trials=100)\n\n# Show results\nfor i, trial in enumerate(best_trials[:3]):\n    print(f\"\\n=== Best Trial {i+1} ===\")\n    print(f\"Model: {trial.params['model_type']}\")\n    print(f\"Quantum F1: {trial.user_attrs.get('Quantum_f1_score', 0):.4f}\")\n    print(f\"Classical F1: {trial.user_attrs.get('Classical_f1_score', 0):.4f}\")\n</code></pre>"},{"location":"examples.html#custom-dataset","title":"Custom Dataset","text":"<p>Loading and processing a custom CSV file:</p> <pre><code>import pandas as pd\nfrom quoptuna import DataPreparation, Optimizer\nfrom quoptuna.backend.utils.data_utils.data import mock_csv_data\n\n# Load custom dataset\ndf = pd.read_csv(\"my_dataset.csv\")\n\n# Explore data\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", df.columns.tolist())\nprint(\"Missing values:\", df.isnull().sum().sum())\n\n# Handle missing values\ndf = df.dropna()\n\n# Transform target to -1 and 1\n# Example: If target is 'Yes'/'No'\ndf[\"target\"] = df[\"outcome\"].map({\"Yes\": 1, \"No\": -1})\n\n# Drop original target column\ndf = df.drop(columns=[\"outcome\"])\n\n# Select features\nfeature_cols = [\"age\", \"income\", \"credit_score\", \"debt_ratio\"]\n\n# Keep only selected columns\ndf = df[feature_cols + [\"target\"]]\n\n# Save processed data\nfile_path = mock_csv_data(df, tmp_path=\"data\", file_name=\"custom_dataset\")\n\n# Prepare for training\ndata_prep = DataPreparation(\n    file_path=file_path,\n    x_cols=feature_cols,\n    y_col=\"target\"\n)\ndata_dict = data_prep.get_data(output_type=\"2\")\n\n# Convert to numpy\nfor key in data_dict.keys():\n    data_dict[key] = data_dict[key].values\n\n# Optimize\noptimizer = Optimizer(\n    db_name=\"custom_experiment\",\n    study_name=\"trial_001\",\n    data=data_dict\n)\nstudy, best_trials = optimizer.optimize(n_trials=100)\n\nprint(f\"\\nFound {len(best_trials)} best trials\")\n</code></pre>"},{"location":"examples.html#shap-analysis","title":"SHAP Analysis","text":"<p>Comprehensive SHAP analysis with all plot types:</p> <pre><code>from quoptuna import XAI\nfrom quoptuna.backend.models import create_model\nfrom quoptuna.backend.xai.xai import XAIConfig\nimport os\n\n# Assuming you have optimized model and data_dict from previous steps\n# Load best trial parameters\nbest_params = best_trials[0].params\n\n# Train model\nmodel = create_model(**best_params)\nmodel.fit(data_dict[\"train_x\"], data_dict[\"train_y\"])\n\n# Configure XAI\nconfig = XAIConfig(\n    use_proba=True,\n    onsubset=True,\n    subset_size=100\n)\n\n# Create XAI instance\nxai = XAI(model=model, data=data_dict, config=config)\n\n# Create output directory\nos.makedirs(\"outputs/shap_plots\", exist_ok=True)\n\n# Generate and save all plot types\nplot_types = [\"bar\", \"beeswarm\", \"violin\", \"heatmap\"]\n\nfor plot_type in plot_types:\n    print(f\"Generating {plot_type} plot...\")\n\n    plot = xai.get_plot(\n        plot_type,\n        max_display=10,\n        class_index=1,\n        save_config={\n            \"save_path\": \"outputs/shap_plots\",\n            \"save_name\": f\"{plot_type}_plot\",\n            \"save_format\": \"png\",\n            \"save_dpi\": 300\n        }\n    )\n\n    print(f\"Saved {plot_type} plot\")\n\n# Generate waterfall plots for first 5 samples\nfor i in range(5):\n    waterfall = xai.get_plot(\n        \"waterfall\",\n        index=i,\n        class_index=1,\n        save_config={\n            \"save_path\": \"outputs/shap_plots\",\n            \"save_name\": f\"waterfall_sample_{i}\",\n            \"save_format\": \"png\",\n            \"save_dpi\": 300\n        }\n    )\n\n    print(f\"Saved waterfall plot for sample {i}\")\n\n# Get classification report\nreport = xai.get_report()\n\nprint(\"\\n=== Classification Report ===\")\nprint(report[\"classification_report\"])\n\n# Plot confusion matrix\nimport matplotlib.pyplot as plt\n\nfig = xai.plot_confusion_matrix()\nplt.savefig(\"outputs/shap_plots/confusion_matrix.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\n\nprint(\"\\nAll SHAP plots saved to outputs/shap_plots/\")\n</code></pre>"},{"location":"examples.html#comparing-models","title":"Comparing Models","text":"<p>Compare quantum vs classical models:</p> <pre><code>from quoptuna import Optimizer\nfrom quoptuna.backend.models import create_model\nimport pandas as pd\n\n# Run optimization (assumes data_dict is prepared)\noptimizer = Optimizer(db_name=\"comparison\", study_name=\"quantum_vs_classical\", data=data_dict)\nstudy, best_trials = optimizer.optimize(n_trials=100)\n\n# Separate quantum and classical trials\nquantum_trials = []\nclassical_trials = []\n\nfor trial in study.get_trials():\n    model_type = trial.params.get(\"model_type\", \"\")\n\n    # Determine if quantum or classical\n    if \"Classifier\" in model_type and any(\n        q in model_type\n        for q in [\"Reuploading\", \"Circuit\", \"Quantum\", \"Kitchen\", \"Dressed\"]\n    ):\n        quantum_trials.append(trial)\n    else:\n        classical_trials.append(trial)\n\n# Compare performance\ndef get_f1_score(trial):\n    q_f1 = trial.user_attrs.get(\"Quantum_f1_score\", 0)\n    c_f1 = trial.user_attrs.get(\"Classical_f1_score\", 0)\n    return max(q_f1, c_f1)\n\n# Get best from each category\nbest_quantum = max(quantum_trials, key=get_f1_score) if quantum_trials else None\nbest_classical = max(classical_trials, key=get_f1_score) if classical_trials else None\n\nprint(\"=== Model Comparison ===\\n\")\n\nif best_quantum:\n    print(\"Best Quantum Model:\")\n    print(f\"  Type: {best_quantum.params['model_type']}\")\n    print(f\"  F1 Score: {get_f1_score(best_quantum):.4f}\")\n    print(f\"  Trial: {best_quantum.number}\")\n\nif best_classical:\n    print(\"\\nBest Classical Model:\")\n    print(f\"  Type: {best_classical.params['model_type']}\")\n    print(f\"  F1 Score: {get_f1_score(best_classical):.4f}\")\n    print(f\"  Trial: {best_classical.number}\")\n\n# Create comparison DataFrame\ncomparison_data = []\n\nfor trial in quantum_trials + classical_trials:\n    comparison_data.append({\n        \"Trial\": trial.number,\n        \"Model Type\": trial.params[\"model_type\"],\n        \"Category\": \"Quantum\" if trial in quantum_trials else \"Classical\",\n        \"F1 Score\": get_f1_score(trial),\n        \"State\": trial.state.name\n    })\n\ndf_comparison = pd.DataFrame(comparison_data)\ndf_comparison = df_comparison.sort_values(\"F1 Score\", ascending=False)\n\nprint(\"\\n=== Top 10 Models ===\")\nprint(df_comparison.head(10))\n\n# Save results\ndf_comparison.to_csv(\"outputs/model_comparison.csv\", index=False)\n</code></pre>"},{"location":"examples.html#report-generation","title":"Report Generation","text":"<p>Generate comprehensive AI reports:</p> <pre><code>from quoptuna import XAI\nfrom quoptuna.backend.xai.xai import XAIConfig\nimport os\n\n# Train model (from previous steps)\nmodel = create_model(**best_trials[0].params)\nmodel.fit(data_dict[\"train_x\"], data_dict[\"train_y\"])\n\n# Create XAI instance\nxai = XAI(\n    model=model,\n    data=data_dict,\n    config=XAIConfig(use_proba=True, onsubset=True, subset_size=50)\n)\n\n# Dataset information for better reports\ndataset_info = {\n    \"Name\": \"Credit Card Approval\",\n    \"URL\": \"https://archive.ics.uci.edu/dataset/143\",\n    \"Description\": \"\"\"\n        This dataset concerns credit card applications.\n        It contains a mix of continuous and categorical features\n        for predicting credit approval decisions.\n    \"\"\",\n    \"Features\": [\"Age\", \"Income\", \"Credit Score\", \"Employment Status\"],\n    \"Target\": \"Approval Decision\",\n    \"Instances\": 690,\n    \"Task\": \"Binary Classification\"\n}\n\n# Generate report with Google Gemini\nreport = xai.generate_report_with_langchain(\n    provider=\"google\",\n    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n    model_name=\"models/gemini-2.0-flash-exp\",\n    dataset_info=dataset_info\n)\n\n# Save report\nwith open(\"outputs/analysis_report.md\", \"w\") as f:\n    f.write(report)\n\nprint(\"Report saved to outputs/analysis_report.md\")\n\n# Generate with OpenAI GPT\nreport_gpt = xai.generate_report_with_langchain(\n    provider=\"openai\",\n    api_key=os.getenv(\"OPENAI_API_KEY\"),\n    model_name=\"gpt-4\",\n    dataset_info=dataset_info\n)\n\nwith open(\"outputs/analysis_report_gpt4.md\", \"w\") as f:\n    f.write(report_gpt)\n\nprint(\"GPT-4 report saved to outputs/analysis_report_gpt4.md\")\n</code></pre>"},{"location":"examples.html#batch-processing","title":"Batch Processing","text":"<p>Process multiple datasets:</p> <pre><code>from quoptuna import DataPreparation, Optimizer\nfrom quoptuna.backend.utils.data_utils.data import mock_csv_data\nimport pandas as pd\nimport os\n\n# List of datasets to process\ndatasets = [\n    {\"id\": 143, \"name\": \"Statlog\"},\n    {\"id\": 176, \"name\": \"Blood\"},\n    {\"id\": 267, \"name\": \"Banknote\"},\n]\n\nresults = []\n\nfor dataset_info in datasets:\n    print(f\"\\n{'='*50}\")\n    print(f\"Processing: {dataset_info['name']}\")\n    print('='*50)\n\n    try:\n        # Fetch dataset\n        from ucimlrepo import fetch_ucirepo\n        dataset = fetch_ucirepo(id=dataset_info[\"id\"])\n\n        # Prepare data\n        X = dataset.data.features\n        y = dataset.data.targets\n        df = pd.concat([X, y], axis=1)\n\n        # Get target column name\n        target_col = dataset.metadata[\"target_col\"][0]\n        df[\"target\"] = df[target_col].replace({0: -1, 1: 1})\n        df = df.drop(columns=[target_col])\n        df = df.dropna()\n\n        # Save\n        file_path = mock_csv_data(\n            df,\n            tmp_path=\"data/batch\",\n            file_name=dataset_info[\"name\"]\n        )\n\n        # Prepare\n        data_prep = DataPreparation(\n            file_path=file_path,\n            x_cols=list(df.columns.difference([\"target\"])),\n            y_col=\"target\"\n        )\n        data_dict = data_prep.get_data(output_type=\"2\")\n\n        # Convert to numpy\n        for key in data_dict.keys():\n            data_dict[key] = data_dict[key].values\n\n        # Optimize\n        optimizer = Optimizer(\n            db_name=f\"batch_{dataset_info['name']}\",\n            study_name=dataset_info[\"name\"],\n            data=data_dict\n        )\n        study, best_trials = optimizer.optimize(n_trials=50)\n\n        # Record results\n        best_f1 = max(\n            best_trials[0].user_attrs.get(\"Quantum_f1_score\", 0),\n            best_trials[0].user_attrs.get(\"Classical_f1_score\", 0)\n        )\n\n        results.append({\n            \"Dataset\": dataset_info[\"name\"],\n            \"Best Model\": best_trials[0].params[\"model_type\"],\n            \"Best F1\": best_f1,\n            \"Trials\": len(study.trials),\n            \"Status\": \"Success\"\n        })\n\n        print(f\"\u2713 Completed: {dataset_info['name']}\")\n        print(f\"  Best F1: {best_f1:.4f}\")\n        print(f\"  Model: {best_trials[0].params['model_type']}\")\n\n    except Exception as e:\n        print(f\"\u2717 Failed: {dataset_info['name']}\")\n        print(f\"  Error: {e}\")\n\n        results.append({\n            \"Dataset\": dataset_info[\"name\"],\n            \"Best Model\": None,\n            \"Best F1\": None,\n            \"Trials\": 0,\n            \"Status\": f\"Failed: {str(e)}\"\n        })\n\n# Save summary\ndf_results = pd.DataFrame(results)\ndf_results.to_csv(\"outputs/batch_processing_results.csv\", index=False)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"BATCH PROCESSING COMPLETE\")\nprint(\"=\"*50)\nprint(df_results)\n</code></pre>"},{"location":"examples.html#advanced-custom-objective-function","title":"Advanced: Custom Objective Function","text":"<p>Define custom optimization objectives:</p> <pre><code>import optuna\nfrom quoptuna.backend.models import create_model\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\ndef custom_objective(trial, data_dict):\n    \"\"\"Custom objective balancing F1 score and model complexity.\"\"\"\n\n    # Suggest model type\n    model_type = trial.suggest_categorical(\n        \"model_type\",\n        [\"SVC\", \"MLPClassifier\", \"DataReuploadingClassifier\"]\n    )\n\n    # Suggest hyperparameters based on model type\n    if model_type == \"SVC\":\n        params = {\n            \"model_type\": model_type,\n            \"C\": trial.suggest_float(\"C\", 0.1, 10.0),\n            \"gamma\": trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n        }\n    elif model_type == \"MLPClassifier\":\n        params = {\n            \"model_type\": model_type,\n            \"hidden_layer_sizes\": trial.suggest_categorical(\n                \"hidden_layer_sizes\",\n                [\"(10,)\", \"(50,)\", \"(10, 10)\"]\n            ),\n            \"alpha\": trial.suggest_float(\"alpha\", 0.0001, 0.1, log=True)\n        }\n    else:  # DataReuploadingClassifier\n        params = {\n            \"model_type\": model_type,\n            \"n_layers\": trial.suggest_int(\"n_layers\", 2, 10),\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.5)\n        }\n\n    # Create and train model\n    model = create_model(**params)\n    model.fit(data_dict[\"train_x\"], data_dict[\"train_y\"])\n\n    # Evaluate\n    y_pred = model.predict(data_dict[\"test_x\"])\n    y_true = data_dict[\"test_y\"]\n\n    # Calculate metrics\n    f1 = f1_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n\n    # Store metrics as user attributes\n    trial.set_user_attr(\"precision\", precision)\n    trial.set_user_attr(\"recall\", recall)\n\n    # Return weighted score\n    # Prefer higher F1 but penalize complex models\n    complexity_penalty = 0.01 if model_type == \"DataReuploadingClassifier\" else 0\n    return f1 - complexity_penalty\n\n# Create study\nstudy = optuna.create_study(direction=\"maximize\")\n\n# Optimize\nstudy.optimize(\n    lambda trial: custom_objective(trial, data_dict),\n    n_trials=100\n)\n\n# Show results\nprint(f\"Best F1 Score: {study.best_value:.4f}\")\nprint(f\"Best Parameters: {study.best_params}\")\nprint(f\"Precision: {study.best_trial.user_attrs['precision']:.4f}\")\nprint(f\"Recall: {study.best_trial.user_attrs['recall']:.4f}\")\n</code></pre>"},{"location":"examples.html#next-steps","title":"Next Steps","text":"<ul> <li>Review the API Reference for detailed class documentation</li> <li>Check the User Guide for the Streamlit interface</li> <li>Visit GitHub for more examples</li> </ul>"},{"location":"user_guide.html","title":"User Guide","text":""},{"location":"user_guide.html#user-guide","title":"User Guide","text":""},{"location":"user_guide.html#introduction","title":"Introduction","text":"<p>QuOptuna is a comprehensive platform for quantum-enhanced machine learning optimization. This guide will walk you through the complete workflow from dataset selection to model analysis and report generation.</p>"},{"location":"user_guide.html#workflow-overview","title":"Workflow Overview","text":"<p>The QuOptuna workflow consists of four main stages:</p> <ol> <li>Dataset Selection - Load and prepare your data</li> <li>Optimization - Find the best hyperparameters</li> <li>Model Training - Train models with optimized parameters</li> <li>SHAP Analysis - Understand and explain model behavior</li> </ol>"},{"location":"user_guide.html#getting-started","title":"Getting Started","text":""},{"location":"user_guide.html#installation","title":"Installation","text":"<p>Install QuOptuna using UV (recommended) or pip:</p> <pre><code># Using UV (recommended)\nuv pip install quoptuna\n\n# Using pip\npip install quoptuna\n</code></pre>"},{"location":"user_guide.html#launching-the-application","title":"Launching the Application","text":"<p>Start the Streamlit interface:</p> <pre><code>quoptuna --start\n</code></pre> <p>Or using Python:</p> <pre><code>python -m quoptuna.frontend.app run\n</code></pre>"},{"location":"user_guide.html#dataset-selection","title":"Dataset Selection","text":""},{"location":"user_guide.html#uci-ml-repository","title":"UCI ML Repository","text":"<p>QuOptuna provides easy access to datasets from the UCI Machine Learning Repository:</p> <ol> <li>Navigate to the Dataset Selection page</li> <li>Select UCI ML Repository tab</li> <li>Choose from popular datasets or enter a custom UCI ID</li> <li>Click Load UCI Dataset</li> </ol> <p>Popular Datasets: - Statlog (Australian Credit Approval) - ID: 143 - Blood Transfusion Service Center - ID: 176 - Banknote Authentication - ID: 267 - Heart Disease - ID: 45 - Ionosphere - ID: 225</p>"},{"location":"user_guide.html#custom-dataset-upload","title":"Custom Dataset Upload","text":"<p>To use your own dataset:</p> <ol> <li>Navigate to the Upload Custom Dataset tab</li> <li>Upload a CSV file</li> <li>Configure target and feature columns</li> <li>Apply target transformation if needed</li> </ol>"},{"location":"user_guide.html#data-configuration","title":"Data Configuration","text":"<p>Important: QuOptuna requires binary classification targets to be encoded as <code>-1</code> and <code>1</code>.</p> <ol> <li>Select Target Column: Choose the column you want to predict</li> <li>Select Features: Choose the features to use for prediction</li> <li>Target Transformation: Map your target values to -1 and 1</li> <li>Handle Missing Values: QuOptuna will automatically remove rows with missing values</li> </ol> <p>Click Save Configuration to proceed to the next step.</p>"},{"location":"user_guide.html#data-preparation-optimization","title":"Data Preparation &amp; Optimization","text":""},{"location":"user_guide.html#data-preparation","title":"Data Preparation","text":"<p>Once your dataset is configured:</p> <ol> <li>Review the dataset summary (rows, columns, target distribution)</li> <li>Click Prepare Data for Training</li> <li>QuOptuna will automatically:</li> <li>Split data into training and test sets</li> <li>Scale features</li> <li>Convert to the format required by models</li> </ol>"},{"location":"user_guide.html#hyperparameter-optimization","title":"Hyperparameter Optimization","text":"<p>Configure and run optimization:</p> <ol> <li>Database Name: Name for storing optimization results</li> <li>Study Name: Unique identifier for this optimization study</li> <li>Number of Trials: How many hyperparameter combinations to try (recommended: 50-200)</li> </ol> <p>Click Start Optimization to begin. This will: - Test multiple model types (both quantum and classical) - Try different hyperparameter combinations - Track the best performing configurations</p> <p>Model Types Tested: - Data Reuploading Classifier (Quantum) - Circuit-Centric Classifier (Quantum) - Quantum Kitchen Sinks (Quantum) - Support Vector Classifier (Classical) - Multi-Layer Perceptron (Classical) - And more...</p>"},{"location":"user_guide.html#understanding-results","title":"Understanding Results","text":"<p>After optimization completes, you'll see: - Best Trials: Top performing configurations - F1 Scores: Performance metrics for quantum and classical approaches - Hyperparameters: The configuration for each trial</p>"},{"location":"user_guide.html#shap-analysis-reporting","title":"SHAP Analysis &amp; Reporting","text":""},{"location":"user_guide.html#trial-selection","title":"Trial Selection","text":"<ol> <li>Navigate to the SHAP Analysis page</li> <li>Select a trial from the dropdown (sorted by performance)</li> <li>Review the trial details and parameters</li> </ol>"},{"location":"user_guide.html#model-training","title":"Model Training","text":"<ol> <li>Click Train Model to train the selected model</li> <li>The model will be trained on your data with the optimized hyperparameters</li> </ol>"},{"location":"user_guide.html#shap-analysis","title":"SHAP Analysis","text":"<p>Configure SHAP analysis:</p> <ul> <li>Use Probability Predictions: Use probability outputs instead of class predictions</li> <li>Use Subset of Data: Analyze a subset for faster computation</li> <li>Subset Size: Number of samples to analyze (recommended: 50-100)</li> </ul> <p>Click Run SHAP Analysis to calculate SHAP values.</p>"},{"location":"user_guide.html#shap-visualizations","title":"SHAP Visualizations","text":"<p>QuOptuna provides multiple visualization types:</p>"},{"location":"user_guide.html#bar-plot","title":"Bar Plot","text":"<p>Shows the mean absolute SHAP value for each feature, indicating overall importance.</p> <p>Use Case: Quick overview of feature importance</p>"},{"location":"user_guide.html#beeswarm-plot","title":"Beeswarm Plot","text":"<p>Shows the distribution of SHAP values, with color indicating feature value (red = high, blue = low).</p> <p>Use Case: Understanding how feature values affect predictions</p>"},{"location":"user_guide.html#violin-plot","title":"Violin Plot","text":"<p>Shows the distribution of SHAP values for each feature.</p> <p>Use Case: Understanding the variability in feature impact</p>"},{"location":"user_guide.html#heatmap","title":"Heatmap","text":"<p>Shows SHAP values for individual instances.</p> <p>Use Case: Instance-level analysis, finding patterns in predictions</p>"},{"location":"user_guide.html#waterfall-plot","title":"Waterfall Plot","text":"<p>Explains how features contribute to a single prediction.</p> <p>Use Case: Understanding individual predictions in detail</p>"},{"location":"user_guide.html#confusion-matrix","title":"Confusion Matrix","text":"<p>Shows classification performance.</p> <p>Use Case: Evaluating overall model accuracy</p>"},{"location":"user_guide.html#report-generation","title":"Report Generation","text":"<p>Generate comprehensive AI-powered reports:</p> <ol> <li>Select LLM Provider: Google (Gemini), OpenAI (GPT), or Anthropic (Claude)</li> <li>Enter API Key: Your API key for the selected provider</li> <li>Model Name: Specific model to use (e.g., \"models/gemini-2.0-flash-exp\")</li> <li>Dataset Information (optional): Add context about your dataset</li> </ol> <p>Click Generate Report to create a detailed analysis report.</p> <p>Report Includes: - Performance metrics analysis - SHAP value interpretation - Feature importance ranking - Risk and fairness assessment - Governance recommendations</p>"},{"location":"user_guide.html#best-practices","title":"Best Practices","text":""},{"location":"user_guide.html#optimization","title":"Optimization","text":"<ul> <li>Start Small: Begin with 50-100 trials to get quick results</li> <li>Increase Gradually: Use 100-200 trials for production models</li> <li>Monitor Performance: Check both quantum and classical model scores</li> <li>Save Studies: Use descriptive names for databases and studies</li> </ul>"},{"location":"user_guide.html#shap-analysis_1","title":"SHAP Analysis","text":"<ul> <li>Use Subsets: Analyze 50-100 samples for faster computation</li> <li>Multiple Plots: Generate several plot types for comprehensive understanding</li> <li>Document Findings: Save plots and reports for future reference</li> <li>Understand Context: Consider domain knowledge when interpreting SHAP values</li> </ul>"},{"location":"user_guide.html#report-generation_1","title":"Report Generation","text":"<ul> <li>Provide Context: Add dataset URL and description for better AI insights</li> <li>Choose Appropriate Models:</li> <li>Fast models (Gemini Flash): Quick exploratory reports</li> <li>Advanced models (GPT-4, Gemini Pro): Detailed production reports</li> <li>Review Carefully: AI-generated reports should be reviewed by domain experts</li> </ul>"},{"location":"user_guide.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide.html#common-issues","title":"Common Issues","text":"<p>Dataset Loading Fails - Check UCI dataset ID is correct - Ensure CSV file is properly formatted - Verify file encoding (UTF-8 recommended)</p> <p>Optimization Errors - Ensure data has no missing values - Check target column has exactly 2 unique values - Verify sufficient samples for train/test split</p> <p>SHAP Analysis Slow - Reduce subset size - Use simpler model types - Check available memory</p> <p>Report Generation Fails - Verify API key is valid - Check internet connection - Ensure model name is correct - Try a different LLM provider</p>"},{"location":"user_guide.html#advanced-features","title":"Advanced Features","text":""},{"location":"user_guide.html#loading-previous-studies","title":"Loading Previous Studies","text":"<p>You can load and analyze previously run optimizations:</p> <ol> <li>Go to the Optimization page</li> <li>Enter the database name and study name</li> <li>Click Load Optimizer</li> <li>Results will be available for analysis</li> </ol>"},{"location":"user_guide.html#batch-processing","title":"Batch Processing","text":"<p>For multiple datasets, you can: 1. Use the Python API directly (see API documentation) 2. Script the workflow using QuOptuna classes 3. Save results to different databases</p>"},{"location":"user_guide.html#custom-models","title":"Custom Models","text":"<p>Advanced users can integrate custom models by: 1. Following the model interface in <code>quoptuna.backend.models</code> 2. Adding model configurations to the optimizer 3. See API documentation for details</p>"},{"location":"user_guide.html#next-steps","title":"Next Steps","text":"<ul> <li>Explore the API Documentation for programmatic usage</li> <li>Check out Examples for common use cases</li> <li>Contribute on GitHub</li> </ul>"},{"location":"user_guide.html#support","title":"Support","text":"<ul> <li>GitHub Issues: Report bugs or request features</li> <li>Documentation: Full documentation</li> <li>Community: Join our discussions on GitHub</li> </ul>"}]}